<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Coding | 逸言]]></title>
  <link href="http://agiledon.github.com/blog/categories/coding/atom.xml" rel="self"/>
  <link href="http://agiledon.github.com/"/>
  <updated>2014-10-28T16:13:34+08:00</updated>
  <id>http://agiledon.github.com/</id>
  <author>
    <name><![CDATA[张逸]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[今天你写了自动化测试吗]]></title>
    <link href="http://agiledon.github.com/blog/2014/10/28/are-you-writing-auto-test-today/"/>
    <updated>2014-10-28T16:08:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2014/10/28/are-you-writing-auto-test-today</id>
    <content type="html"><![CDATA[<p>{% img center /images/2014/ship.jpg %}</p>

<p>一艘货轮满载着货物从港口启航，向浩瀚的大海深处破水而去。海面平静，微微皱起波浪，从容而显得宽容。然而，货轮的步履却有些蹒跚，发动机“轰轰轰”地嘶吼着，不堪重负，却无法让船只游得更快，倒像是海水咬住了船底往下在拖曳。</p>

<p>“嘟——嘟——嘟”，突然警报声响起，甲板上变得喧闹起来，一个水手模样的年轻人声嘶力竭地呐喊：“船超重了，快快快……快卸货！”声音急迫，甚至能听到哭音。然后，又是一阵喧嚷，似乎是在争吵甚么，就看到一个胖胖的中年人冲了出来。看他那肥胖的体型，真难想到他的身手竟然如此敏捷，如海豹一般破开人群，两手挥舞，大声喊道：“怎么了？怎么了？”，他停下来，吼道：“我看哪个不长眼的家伙敢卸我的货！谁敢！”</p>

<p>船长走了过来，略带恭敬地对那中年人说道：“老板，你看，这船超载了，船身吃紧，已经发出超重警报了。倘若不减轻船的重量，这船开不了多久就得沉了啊！”</p>

<p>“他奶奶的，这船可真秀气啊！”中年人一边骂骂咧咧，却也知道形势紧迫，容不得自己不下决断。可是心里总存着侥幸心理，突然灵机一动，一把拉过船长，指着这艘货轮问道：“既然这船超重，那我问你，除了货物，这船上还有哪些东西占了船身的重量？”</p>

<p>船长一听，立刻明白老板心里的小九九，没好气地回道：“除了货物，占了这船重量的就还有人、淡水、食品，还有救生圈、救生衣、救生艇。老板你看那样不顺心，你就扔哪样吧！”</p>

<p>嘿，回到现实中来吧。回答问题：倘若你是老板，你会扔哪样呢？稍有理智的人，都不难做出正确的选择。——然而，为何在软件开发过程中，我却常常看到有人选择丢弃救生圈、救生衣、救生艇呢？哪怕它们的重量对于整艘船而言如同九牛一毛，却总有人存着侥幸，认为船就超了那么一点点，或许扔出几个救生圈，就能恢复重量到安全线；于是，货物得以幸存，可以避免不必要的损失了。</p>

<p>或许，我们没这么傻吧。那么，让我们想想。</p>

<p>假设将这航行比作是软件开发的过程，那么载货到达目的地，就是实现软件需求。只有交付了货物，才算是实现了价值。至于淡水、食品以及船只，就是开发的工具与环境，而救生圈、救生衣、救生艇，就是我们在开发过程中需要编写的自动化测试（单元测试、集成测试、验收测试等）。我们需要这些测试来随时检测开发功能是否有误，及时反馈，就像在航行过程中，若是有人溺水，可以用救生衣、救生圈挽回一条生命一般。</p>

<p>可一旦开发时间紧促，人手严重不足，进度压力山大时，我们想到了什么呢？对于我见过的多数软件团队而言，每当面临如此窘境时，首先想到的就是减少甚至不做自动化测试。有人认为自动化测试没有价值，浪费成本；有人认为自动化测试可以以后再补，先把功能完成再说；有人认为有了手动测试，就足以保障项目的质量……如此这般，自动化测试就这般被忽略了，沦落到随时可以抛弃的地位。</p>

<p>倘若软件开发就只有这一个阶段，没有需求变更，没有后续开发，没有软件维护。项目的代码库如树苗一般在阳光雨露下茁壮成长，没有大风狂吹，没有烈日暴晒，没有大雨倾盆，亦没有虫蚁啃啮，那自然由得它去。然而，现实世界哪有如此美好！</p>

<p>Michael Feather将没有自动化测试的代码称为“遗留代码”，温伯格在《咨询的奥秘》中则认为应该将“维护”工作视为“设计”工作。自动化测试是修改的基础，重构的保障，设计的规约，演化的文档。它的重要性怎么强调都不过分，然而很可惜，在很多软件项目开发中，它甚至不如“鸡肋”的地位，说放弃就放弃了，在决定当时，毫不觉得可惜。至于以后的以后，不远的未来，谁还顾得上！！？债欠下了，什么时候偿还呢？——不知道！到了催债的那天，再想办法还债吧。</p>

<p>鸵鸟心态害死人啊！</p>

<p>扪心自问，我们经历过维护的苦楚吗？体验过修改代码的烦恼吗？修复过不胜其扰的缺陷吗？答案若是肯定，那么，如果老天再给你一次机会，把选择自动化测试的权利放在你面前，作为“曾经沧海难为水”的你，你会怎么选？——所以，我想问问程序员们：今天，你写自动化测试了吗？</p>

<p>后记：其实我很想写：程序员要是写代码不写测试，就是耍流氓，就是做爱不带套。可我纯洁啊，没好意思写出来。可总觉得这么经典的语录藏在我心里，小心憋不住。把心一横，他奶奶的，毕竟话糙理不糙啊！这不，一激动，还是吐露真言了。终归脸皮薄，没好意思写进正文，就这般猥琐地躲在文章后面，算是偷窥，觑觑究竟有谁真有耐心读到文章末尾，听听我的真心大实话。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[快速了解Scala技术栈]]></title>
    <link href="http://agiledon.github.com/blog/2014/09/22/understanding-scala-stack/"/>
    <updated>2014-09-22T15:31:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2014/09/22/understanding-scala-stack</id>
    <content type="html"><![CDATA[<p>我无可救药地成为了Scala的超级粉丝。在我使用Scala开发项目以及编写框架后，它就仿佛凝聚成为一个巨大的黑洞，吸引力使我不得不飞向它，以至于开始背离Java。固然Java 8为Java阵营增添了一丝亮色，却是望眼欲穿，千呼万唤始出来。而Scala程序员，却早就在享受lambda、高阶函数、trait、隐式转换等带来的福利了。</p>

<p>Java像是一头史前巨兽，它在OO的方向上几乎走到了极致，硬将它拉入FP阵营，确乎有些强人所难了。而Scala则不，因为它的诞生就是OO与FP的混血儿——完美的基因融合。</p>

<p>“Object-Oriented Meets Functional”，这是Scala语言官方网站上飘扬的旗帜。这也是Scala的野心，当然，也是Martin Odersky的雄心。</p>

<h2>Scala社区的发展</h2>

<p>然而，一门语言并不能孤立地存在，必须提供依附的平台，以及围绕它建立的生态圈。不如此，语言则不足以壮大。Ruby很优秀，但如果没有Ruby On Rails的推动，也很难发展到今天这个地步。Scala同样如此。反过来，当我们在使用一门语言时，也要选择符合这门语言的技术栈，在整个生态圈中找到适合具体场景的框架或工具。</p>

<p>当然，我们在使用Scala进行软件开发时，亦可以寻求庞大的Java社区支持；可是，如果选择调用Java开发的库，就会牺牲掉Scala给我们带来的福利。幸运的是，在如今，多数情况你已不必如此。伴随着Scala语言逐渐形成的Scala社区，已经开始慢慢形成相对完整的Scala技术栈。无论是企业开发、自动化测试或者大数据领域，这些框架或工具已经非常完整地呈现了Scala开发的生态系统。</p>

<!-- more -->


<h2>快速了解Scala技术栈</h2>

<p>若要了解Scala技术栈，并快速学习这些框架，一个好的方法是下载typesafe推出的Activator。它提供了相对富足的基于Scala以及Scala主流框架的开发模板，这其中实则还隐含了typesafe为Scala开发提供的最佳实践与指导。下图是Activator模板的截图：
{% img center /images/2014/activatortemplate.png %}</p>

<p>那么，是否有渠道可以整体地获知Scala技术栈到底包括哪些框架或工具，以及它们的特性与使用场景呢？感谢Lauris Dzilums以及其他在Github的Contributors。在Lauris Dzilums的Github上，他建立了名为awesome-scala的<a href="https://github.com/lauris/awesome-scala">Repository</a>，搜罗了当下主要的基于Scala开发的框架与工具，涉及到的领域包括：
Database
Web Frameworks
i18n
Authentication
Testing
JSON Manipulation
Serialization
Science and Data Analysis
Big Data
Functional Reactive Programming
Modularization and Dependency Injection
Distributed Systems
Extensions
Android
HTTP
Semantic Web
Metrics and Monitoring
Sbt plugins</p>

<p>是否有“乱花渐欲迷人眼”的感觉？不是太少，而是太多！那就让我删繁就简，就我的经验介绍一些框架或工具，从持久化、分布式系统、HTTP、Web框架、大数据、测试这六方面入手，作一次蜻蜓点水般的俯瞰。</p>

<h3>持久化</h3>

<p>归根结底，对数据的持久化主要还是通过JDBC访问数据库。但是，我们需要更好的API接口，能更好地与Scala契合，又或者更自然的ORM。如果希望执行SQL语句来操作数据库，那么运用相对广泛的是框架ScalikeJDBC，它提供了非常简单的API接口，甚至提供了SQL的DSL语法。例如：
{% codeblock lang:scala %}
  val alice: Option[Member] = withSQL {</p>

<pre><code>select.from(Member as m).where.eq(m.name, name)
</code></pre>

<p>  }.map(rs => Member(rs)).single.apply()
{% endcodeblock %}</p>

<p>如果希望使用ORM框架，Squeryl应该是很好的选择。我的同事杨云在项目中使用过该框架，体验不错。该框架目前的版本为0.9.5，已经比较成熟了。Squeryl支持按惯例映射对象与关系表，相当于定义一个POSO（Plain Old Scala Object），从而减少框架的侵入。若映射违背了惯例，则可以利用框架定义的annotation如@Column定义映射。框架提供了org.squeryl.Table[T]来完成这种映射关系。</p>

<p>因为可以运用Scala的高阶函数、偏函数等特性，使得Squeryl的语法非常自然，例如根据条件对表进行更新：
{% codeblock lang:scala %}
update(songs)(s =>
  where(s.title === "Watermelon Man")
  set(s.title := "The Watermelon Man",</p>

<pre><code>  s.year  := s.year.~ + 1)
</code></pre>

<p>)
{% endcodeblock %}</p>

<h3>分布式系统</h3>

<p>我放弃介绍诸如模块化管理以及依赖注入，是因为它们在Scala社区的价值不如Java社区大。例如，我们可以灵活地运用trait结合cake pattern就可以实现依赖注入的特性。因此，我直接跳过这些内容，来介绍影响更大的支持分布式系统的框架。</p>

<p>Finagle的血统高贵，来自过去的寒门，现在的高门大族Twitter。Twitter是较早使用Scala作为服务端开发的互联网公司，因而积累了非常多的Scala经验，并基于这些经验推出了一些颇有影响力的框架。由于Twitter对可伸缩性、性能、并发的高要求，这些框架也极为关注这些质量属性。Finagle就是其中之一。它是一个扩展的RPC系统，以支持高并发服务器的搭建。我并没有真正在项目中使用过Finagle，大家可以到它的官方网站获得更多消息。</p>

<p>对于分布式的支持，绝对绕不开的框架还是AKKA。它产生的影响力如此之大，甚至使得Scala语言从2.10开始，就放弃了自己的Actor模型，转而将AKKA Actor收编为2.10版本的语言特性。许多框架在分布式处理方面也选择了使用AKKA，例如Spark、Spray。AKKA的Actor模型参考了Erlang语言，为每个Actor提供了一个专有的Mailbox，并将消息处理的实现细节做了良好的封装，使得并发编程变得更加容易。AKKA很好地统一了本地Actor与远程Actor，提供了几乎一致的API接口。AKKA也能够很好地支持消息的容错，除了提供一套完整的Monitoring机制外，还提供了对Dead Letter的处理。</p>

<p>AKKA天生支持EDA（Event-Driven Architecture）。当我们针对领域建模时，可以考虑针对事件进行建模。在AKKA中，这些事件模型可以被定义为Scala的case class，并作为消息传递给Actor。借用Vaughn Vernon在《实现领域驱动设计》中的例子，针对如下的事件流：
{% img center /images/2014/pipe-filter.jpg %}</p>

<p>我们可以利用Akka简单地实现：
{% codeblock lang:scala %}
case class AllPhoneNumberListed(phoneNumbers: List[Int])
case class PhoneNumberMatched(phoneNumbers: List[Int])
case class AllPhoneNumberRead(fileName: String)</p>

<p>class PhoneNumbersPublisher(actor: ActorRef) extends ActorRef {</p>

<pre><code>def receive = {
    case ReadPhoneNumbers =&gt;
    //list phone numbers

    actor ! AllPhoneNumberListed(List(1110, ))
}
</code></pre>

<p>}</p>

<p>class PhoneNumberFinder(actor: ActorRef) extends ActorRef {</p>

<pre><code>def receive = {
    case AllPhoneNumberListed(numbers) =&gt; 
        //match

        actor ! PhoneNumberMatched()
}
</code></pre>

<p>}</p>

<p>val finder = system.actorOf(Prop(new PhoneNumberFinder(...)))
val publisher = system.actorOf(Prop(new PhoneNumbersPublisher(finder)))</p>

<p>publisher ! ReadPhoneNumbers("callinfo.txt")
{% endcodeblock %}</p>

<p>若需要处理的电话号码数据量大，我们可以很容易地将诸如PhoneNumbersPublisher、PhoneNumberFinder等Actors部署为Remote Actor。此时，仅仅需要更改客户端获得Actor的方式即可。</p>

<p>Twitter实现的Finagle是针对RPC通信，Akka则提供了内部的消息队列（MailBox），而由LinkedIn主持开发的Kafka则提供了支持高吞吐量的分布式消息队列中间件。这个顶着文学家帽子的消息队列，能够支持高效的Publisher-Subscriber模式进行消息处理，并以快速、稳定、可伸缩的特性很快引起了开发者的关注，并在一些框架中被列入候选的消息队列而提供支持，例如，Spark Streaming就支持Kafka作为流数据的Input Source。</p>

<h3>HTTP</h3>

<p>严格意义上讲，Spray并非单纯的HTTP框架，它还支持REST、JSON、Caching、Routing、IO等功能。Spray的模块及其之间的关系如下图所示：
{% img center /images/2014/spraydepencies.png %}</p>

<p>我在项目中主要将Spray作为REST框架来使用，并结合AKKA来处理领域逻辑。Spray处理HTTP请求的架构如下图所示：
{% img center /images/2014/spray_arch.png %}</p>

<p>Spray提供了一套DSL风格的path语法，能够非常容易地编写支持各种HTTP动词的请求，例如：
{% codeblock lang:scala %}
trait HttpServiceBase extends Directives with Json4sSupport {</p>

<pre><code> implicit val system: ActorSystem
 implicit def json4sFormats: Formats = DefaultFormats
 def route: Route
</code></pre>

<p>}</p>

<p>trait CustomerService extends HttpServiceBase {</p>

<pre><code> val route = 
      path("customer" / "groups") {
           get {
                parameters('groupids.?) {
                     (groupids) =&gt;
                          complete {
                               groupids match {
                                    case Some(groupIds) =&gt; 
                ViewUserGroup.queryUserGroup(groupIds.split(",").toList)
                                    case None =&gt; ViewUserGroup.queryUserGroup()
                               }
                          }
                }
           }
      } ~
      path("customers" / "vip" / "failureinfo") {
           post {
                entity(as[FailureVipCustomerRequest]) {
                     request =&gt; 
                          complete {
                               VipCustomer.failureInfo(request) 
                          }
                }
           }
      }
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>我个人认为，在进行Web开发时，完全可以放弃Web框架，直接选择AngularJS结合Spray和AKKA，同样能够很好地满足Web开发需要。</p>

<p>Spray支持REST，且Spray自身提供了服务容器spray-can，因而允许Standalone的部署（当然也支持部署到Jetty和tomcat等应用服务器）。Spray对HTTP请求的内部处理机制实则是基于Akka-IO，通过IO这个Actor发出对HTTP的bind消息。例如：
{% codeblock lang:scala %}
 IO(Http) ! Http.Bind(service, interface = "0.0.0.0", port = 8889)
{% endcodeblock %}</p>

<p>我们可以编写不同的Boot对象去绑定不同的主机Host以及端口。这些特性都使得Spray能够很好地支持当下较为流行的Micro Service架构风格。</p>

<h3>Web框架</h3>

<p>正如前面所说，当我们选择Spray作为REST框架时，完全可以选择诸如AngularJS或者Backbone之类的JavaScript框架开发Web客户端。客户端能够处理自己的逻辑，然后再以JSON格式发送请求给REST服务端。这时，我们将模型视为资源（Resource），视图完全在客户端。JS的控制器负责控制客户端的界面逻辑，服务端的控制器则负责处理业务逻辑，于是传统的MVC就变化为VC+R+C模式。这里的R指的是Resource，而服务端与客户端则通过JSON格式的Resource进行通信。</p>

<p>若硬要使用专有的Web框架，在Scala技术栈下，最为流行的就是Play Framework，这是一个标准的MVC框架。另外一个相对小众的Web框架是Lift。它与大多数Web框架如RoR、Struts、Django以及Spring MVC、Play不同，采用的并非MVC模式，而是使用了所谓的View First。它驱动开发者对内容生成与内容展现（Markup）形成“关注点分离”。</p>

<p>Lift将关注点重点放在View上，这是因为在一些Web应用中，可能存在多个页面对同一种Model的Action。倘若采用MVC中的Controller，会使得控制变得非常复杂。Lift提出了一种所谓view-snippet-model（简称为VSM）的模式。
{% img center /images/2014/lift_vsm.png %}</p>

<p>View主要为响应页面请求的HTML内容，分为template views和generated views。Snippet的职责则用于生成动态内容，并在模型发生更改时，对Model和View进行协调。</p>

<h3>大数据</h3>

<p>大数据框架最耀眼的新星非Spark莫属。与许多专有的大数据处理平台不同，Spark建立在统一抽象的RDD之上，使得它可以以基本一致的方式应对不同的大数据处理场景，包括MapReduce，Streaming，SQL，Machine Learning以及Graph等。这即Matei Zaharia所谓的“设计一个通用的编程抽象（Unified Programming Abstraction）。
{% img center /images/2014/spark_architecture.jpg %}</p>

<p>由于Spark具有先进的DAG执行引擎，支持cyclic data flow和内存计算。因此相比较Hadoop而言，性能更优。在内存中它的运行速度是Hadoop MapReduce的100倍，在磁盘中是10倍。</p>

<p>由于使用了Scala语言，通过高效利用Scala的语言特性，使得Spark的总代码量出奇地少，性能却在多数方面都具备一定的优势（只有在Streaming方面，逊色于Storm）。下图是针对Spark 0.9版本的BenchMark：
{% img center /images/2014/spark_metric.png %}</p>

<p>由于使用了Scala，使得语言的函数式特性得到了最棒的利用。事实上，函数式语言的诸多特性包括不变性、无副作用、组合子等，天生与数据处理匹配。于是，针对WordCount，我们可以如此简易地实现：
{% codeblock lang:scala %}
file = spark.textFile("hdfs://...")</p>

<p>file.flatMap(line => line.split(" "))</p>

<pre><code>.map(word =&gt; (word, 1))
.reduceByKey(_ + _)
</code></pre>

<p>{% endcodeblock %}</p>

<p>要是使用Hadoop，就没有这么方便了。幸运的是，Twitter的一个开源框架scalding提供了对Hadoop MapReduce的抽象与包装。它使得我们可以按照Scala的方式执行MapReduce的Job：
{% codeblock lang:scala %}
class WordCountJob(args : Args) extends Job(args) {
  TextLine( args("input") )</p>

<pre><code>.flatMap('line -&gt; 'word) { line : String =&gt; tokenize(line) }
.groupBy('word) { _.size }
.write( Tsv( args("output") ) )
</code></pre>

<p>  // Split a piece of text into individual words.
  def tokenize(text : String) : Array[String] = {</p>

<pre><code>// Lowercase each word and remove punctuation.
text.toLowerCase.replaceAll("[^a-zA-Z0-9\\s]", "").split("\\s+")
</code></pre>

<p>  }
}
{% endcodeblock %}</p>

<h3>测试</h3>

<p>虽然我们可以使用诸如JUnit、TestNG为Scala项目开发编写单元测试，使用Cocumber之类的BDD框架编写验收测试。但在多数情况下，我们更倾向于选择使用ScalaTest或者Specs2。在一些Java开发项目中，我们也开始尝试使用ScalaTest来编写验收测试，乃至于单元测试。</p>

<p>若要我选择ScalaTest或Specs2，我更倾向于ScalaTest，这是因为ScalaTest支持的风格更具备多样性，可以满足各种不同的需求，例如传统的JUnit风格、函数式风格以及Spec方式。我的一篇博客《ScalaTest的测试风格》详细介绍了各自的语法。</p>

<p>一个被广泛使用的测试工具是Gatling，它是基于Scala、AKKA以及Netty开发的性能测试与压力测试工具。我的同事刘冉在InfoQ发表的文章《新一代服务器性能测试工具Gatling》对Gatling进行了详细深入的介绍。</p>

<p>ScalaMeter也是一款很不错的性能测试工具。我们可以像编写ScalaTest测试那样的风格来编写ScalaMeter性能测试用例，并能够快捷地生成性能测试数据。这些功能都非常有助于我们针对代码或软件产品进行BenchMark测试。我们曾经用ScalaMeter来编写针对Scala集合的性能测试，例如比较Vector、ArrayBuffer、ListBuffer以及List等集合的相关操作，以便于我们更好地使用Scala集合。以下代码展示了如何使用ScalaMeter编写性能测试：
{% codeblock lang:scala %}
import org.scalameter.api._</p>

<p>object RangeBenchmark
extends PerformanceTest.Microbenchmark {
  val ranges = for {</p>

<pre><code>size &lt;- Gen.range("size")(300000, 1500000, 300000)
</code></pre>

<p>  } yield 0 until size</p>

<p>  measure method "map" in {</p>

<pre><code>using(ranges) curve("Range") in {
  _.map(_ + 1)
}
</code></pre>

<p>  }
}
{% endcodeblock %}</p>

<h2>根据场景选择框架或工具</h2>

<p>比起Java庞大的社区，以及它提供的浩如烟海般的技术栈，Scala技术栈差不多可以说是沧海一粟。然而，麻雀虽小却五脏俱全，何况Scala以及Scala技术栈仍然走在迈向成熟的道路上。对于Scala程序员而言，因为项目的不同，未必能涉猎所有技术栈，而且针对不同的方面，也有多个选择。在选择这些框架或工具时，应根据实际的场景做出判断。为稳妥起见，最好能运用技术矩阵地方式对多个方案进行设计权衡与决策。</p>

<p>我们也不能固步自封，视Java社区而不顾。毕竟那些Java框架已经经历了千锤百炼，并有许多成功的案例作为佐证。关注Scala技术栈，却又不局限自己的视野，量力而为，选择合适的技术方案，才是设计与开发的正道。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[测试数据准备框架]]></title>
    <link href="http://agiledon.github.com/blog/2014/08/03/test-data-prepare-framework/"/>
    <updated>2014-08-03T21:25:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2014/08/03/test-data-prepare-framework</id>
    <content type="html"><![CDATA[<p>{% img center /images/2014/sisyphus.jpg %}</p>

<p>这是我去年写的一个小框架，专为自动化测试准备数据。以我个人的经验，进行自动化测试尤其是单元测试，除了技能的障碍外，最大的障碍有两点：1)难以解除依赖，因而无法为相关功能编写独立的测试；2)数据准备困难，导致编写测试的成本高。在我的一篇博客《<a href="http://agiledon.github.io/blog/2013/12/25/thought-about-applying-tdd/">推行TDD的思考</a>》中有相关总结。尤其在企业级软件系统中，面对的领域相对复杂，被测接口常常需要输入复杂的数据，然后再返回复杂的数据。在面向对象开发中，这些数据常常被建模为对象。我们该怎么实例化这些对象？在单元测试中，我们常常会引入Builder模式，通过Fluent Interface的方式建立类似DSL的构建接口，以便于自由、流畅而可任意组合的方式，帮助编写测试的人实例化他想要创建的对象。然而，一旦这个对象内嵌了多层，或具有极多的属性时，创建就变得极为艰难了。</p>

<p>在ThoughtWorks的一些项目中，尝试使用Yaml来准备数据。有一个极好的框架snakeyaml可以很好地支持我们处理yaml文件。正是基于此，启发我开发了这样一个小框架Sisyphus。它可以帮助更方便地以各种文件形式来准备数据，并提供了统一的接口。目前，支持的格式为我们最常使用的yaml与json。</p>

<p>框架的开发并没有什么技术含量，但框架提供的功能却是基于实际项目中面临的困难逐步演化出来的。例如框架提供的模板功能，数据分节功能，在一开始并没有想到。正是因为这两个功能，让我觉得这个框架还有一些用处。之所以将这个框架命名为Sisyphus，缘由在于我将测试数据视为西西弗推动的那一块大石头，无法承受的如命运一般的沉重，却又不得不用力去承受，如此往返以致时时刻刻。</p>

<!-- more -->


<p>要使用Sisyphus，可以在build.gradle的构建脚本中添加sonatype提供的Repository依赖：
{% codeblock lang:groovy %}
repositories {</p>

<pre><code>maven{
    url 'https://oss.sonatype.org/content/groups/public'
}
mavenCentral();
</code></pre>

<p>}</p>

<p>dependencies {</p>

<pre><code>test (
        'junit:junit:4.11',
        'com.github.agiledon:sisyphus:1.0-SNAPSHOT'
    )
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>针对Yaml文件，我选择了snakeyaml框架。而对于Json数据，我尝试了两种框架Jackson和Gson。我发现这两个框架各有不足之处。倘若使用Jackson，它要求你要反序列化的类型必须定义默认的构造函数，如果没有定义，则必须声明Annotation：@JsonCreate和@JsonProperty。可是，有时候我们要准备的数据对象，或许是自动生成的，并不能修改该定义。何况，为了进行测试而改变产品代码，是邪恶的，不可取。Gson没有这样的约束，但当我尝试将一段字符串解析为byte[]类型时，发现Gson并不支持。为此，Sisyphus为Json数据提供了两种实现，为了区分，若是Gson实现，则要求测试数据文件的扩展名必须为“.gson”。</p>

<p>模板功能使用了ST4的StringTemplate。我没有使用该框架提供的默认变量标识，而是要求将变量用$符号包裹起来。如果不需要模板，则只需提供一个测试数据文件即可；否则还要定义模板文件，它的扩展名为“.template”。例如针对Json格式的数据，倘若定义了这样的User类：
{% codeblock lang:java %}
public class User {</p>

<pre><code>public enum Gender { MALE, FEMALE };

public static class Name {
    private String _first, _last;

    public String getFirst() { return _first; }
    public String getLast() { return _last; }

    public void setFirst(String s) { _first = s; }
    public void setLast(String s) { _last = s; }
}

private Gender _gender;
private Name _name;
private boolean _isVerified;
private byte[] _userImage;

public Name getName() { return _name; }
public boolean isVerified() { return _isVerified; }
public Gender getGender() { return _gender; }
public byte[] getUserImage() { return _userImage; }

public void setName(Name n) { _name = n; }
public void setVerified(boolean b) { _isVerified = b; }
public void setGender(Gender g) { _gender = g; }
public void setUserImage(byte[] b) { _userImage = b; }
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>则可以准备模板文件为：
{% codeblock %}
{
  "name" : { "first" : $firstName$, "last" : $lastName$ },
  "gender" : "MALE",
  "verified" : false,
  "userImage" : "Rm9vYmFyIQ=="
}
{% endcodeblock %}</p>

<p>而数据文件则可以是：
{% codeblock %}</p>

<h1>This is multi section sample</h1>

<p>firstName = "Joe"
lastName = "Sixpack"</p>

<p>///</p>

<p>firstName = "Bruce"
lastName = "Zhang"</p>

<p>///</p>

<p>firstName = "Yi"
lastName = "Zhang"
{% endcodeblock %}</p>

<p>符号///是分节的标识符，而符号#则为注释，读取数据时会忽略该符号后的所有字符。使用Sisyphus框架，就可以很方便地加载数据文件，从而获得三个User实例。如下测试：
{% codeblock lang:java %}</p>

<pre><code>@Test
public void should_compose_multi_user_data_by_parsing_template_file() {
    List&lt;User&gt; users = Fixture.from("userWithMultiSections.json")
            .withTemplate("template/user.template")
            .toList(User.class);
    assertThat(users, not(nullValue()));
    assertThat(users.get(0).getName().getFirst(), is("Joe"));
    assertThat(users.get(0).getName().getLast(), is("Sixpack"));
    assertThat(users.get(2).getName().getFirst(), is("Yi"));
    assertThat(users.get(2).getName().getLast(), is("Zhang"));
}
</code></pre>

<p>{% endcodeblock %}</p>

<p>Sisyphus框架还提供了将实例化好的对象输出为对应格式数据文件的功能。这个功能算是框架提供的一个辅助功能，可以避免手动去准备数据文件。例如我们可以先创建一个User实例，将其输出为yaml格式的数据文件，从而将该文件作为测试数据文件：
{% codeblock lang:java %}
   @Test</p>

<pre><code>public void should_serialize_specific_object_to_string_with_yaml_format() {
    User user = createUser();
    String result = FixtureAssist.yaml().print(user, "outputUser");
    assertThat(result, is("!!com.github.agiledon.sisyphus.domain.json.User\n" +
            "gender: MALE\n" +
            "name: {first: Yi, last: Zhang}\n" +
            "userImage: !!binary |-\n" +
            "  MDAwMDExMTE=\n" +
            "verified: true\n"));
}
</code></pre>

<p>{% endcodeblock %}</p>

<p>框架在加载数据文件时，本身提供了缓存功能，如果重复加载同一个文件，则第二次加载时，并不需要真正去读取文件，从而在一定程度上提高了测试的效率。</p>

<p>框架的入口为Fixture类。若要使用Sisyphus准备数据，通常应调用Fixture的静态方法。框架也提供了对JUnit的支持，通过框架自定义的Rule来加载测试数据，使用方式为：
{% codeblock lang:java %}
public class DataProviderRuleTest {</p>

<pre><code>@Rule
public DataProviderRule dataProvider = new DataProviderRule();

@Test
@DataResource(resourceName = "user.json", targetClass = User.class)
public void should_compose_User_data_with_json_format() {
    User user = dataProvider.provideData();
    assertThat(user, not(nullValue()));
    assertThat(user.getName().getFirst(), is("Joe"));
}

@Test
@DataResource(resourceName = "userWithTemplate.json",
        templateName = "template/user.template",
        targetClass = User.class)
public void should_compose_user_data_by_parsing_template_file() {
    User user = dataProvider.provideData();
    assertThat(user, not(nullValue()));
    assertThat(user.getName().getFirst(), is("Joe"));
    assertThat(user.getName().getLast(), is("Sixpack"));
}
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>但我个人并不推荐这种方式。使用Fixture更直观，甚至更简单。Sisyphus的源代码可以从<a href="https://github.com/agiledon/sisyphus">我的Github</a>上获得，在其Repository主页，有更多实例介绍。你也可以clone代码后，通过测试代码学习框架的使用。clone代码到本地后，将当前目录转到sisyphus，然后运行gradle build，即可对代码进行编译。若需运行测试，可运行gradle test。由于我使用的IDE为IntelliJ Idea，因此，框架的构建脚本中仅支持IDEA。你可以通过运行gradle idea来生成IntelliJ的项目。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scala学习资源]]></title>
    <link href="http://agiledon.github.com/blog/2014/07/20/scala-resource/"/>
    <updated>2014-07-20T22:17:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2014/07/20/scala-resource</id>
    <content type="html"><![CDATA[<h2>网站</h2>

<p>Twitter提供的<a href="http://twitter.github.io/scala_school/zh_cn/basics.html">Scala School</a>：讲解简洁，可以作为快速入门</p>

<p>Twitter编写的如何有效开发Scala的文档——<a href="http://twitter.github.io/effectivescala/index.html">Effective Scala</a></p>

<p>一个非常棒的<a href="http://zh.scala-tour.com">Scala网上教程</a>：可以直接在网页上修改程序和运行程序</p>

<p>很好的<a href="http://www.artima.com/index.jsp">Scala社区网站</a>：只是最近似乎很少更新</p>

<p>当然，不能忘记了Scala的<a href="http://www.scala-lang.org/documentation/">官方网站提供的文档</a>：这或许可以说是最权威的内容，同时，也会提供最新的内容</p>

<p>我自己整理的<a href="https://github.com/agiledon/scala_coding_convention">Scala编码规范与最佳实践</a>：是我结合项目情况并参考相关书籍和文章，以及个人的体会整理的。内容在不断更新中。若愿意贡献一份力量，可以和我联系，我可以加你为Contributor。</p>

<h2>博客</h2>

<p>Alvin Alexander的<a href="http://alvinalexander.com/scala">博客</a>：内有诸多Scala文章，Alvin是Scala Cookbook一书的作者</p>

<p>阿里巴巴Hongjiang的<a href="http://hongjiang.info/scala/">博客</a>：有很多成系列的Scala文章</p>

<h2>视频与教程</h2>

<p>Scala之父Martin Odersky在<a href="https://www.coursera.org/course/progfun">Scala教学视频</a>。你还可以在<a href="http://www.gtan.com/welfare05.html">国内的这个网站</a>上在线观看，在这个网站上，你还能阅读到Akka文档的中文版。</p>

<p>你还可以通过<a href="http://www.typesafe.com/activator">下载Activator</a>，然后通过运行activator，生成各式各样的Scala开发模板（包括Play、Akka、Spray、Spark）。生成的模板有代码和简明教程。</p>

<p>若想更扎实的掌握函数式编程，可以在学习Scala之前，先学习Heskell。
学习<a href="http://learnyouahaskell.com/chapters">Heskell的在线书</a>：写得简洁易懂，很生动。可以作为heskell的入门书籍</p>

<h2>书籍</h2>

<p>如果你希望快速地了解Scala的语法，可以阅读《<a href="http://book.douban.com/subject/19971952/">快学Scala</a>》，即Scala for the I'mpatient；但是，如果你希望了解真正的Scala精髓，那么奉劝大家不要阅读此书，而应该阅读Scala宝典，由Martin Odersky亲自撰写的著作<a href="http://book.douban.com/subject/3338669/">Programming in Scala</a>。不要阅读此书的中文版，翻译实在糟糕。</p>

<p>如果你想要深入理解Scala的内在机制，可以阅读<a href="http://book.douban.com/subject/6962379/">Scala in Depth</a>；我的同事<a href="http://kaopua.com/blog/">诺铁</a>翻译了此书，即日出版。</p>

<p>如果你想了解更多Scala的案例运用，可以阅读<a href="http://book.douban.com/subject/20876182/">Scala Cookbook</a>。书中提供了大量的案例。</p>

<p>如果你想了解Scala的函数式运用，请阅读Paul Chiusano撰写的<a href="http://book.douban.com/subject/20488750/">Functional Programming in Scala</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ListBuffer vs List in Scala]]></title>
    <link href="http://agiledon.github.com/blog/2014/07/07/using-listbuffer-vs-list/"/>
    <updated>2014-07-07T19:19:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2014/07/07/using-listbuffer-vs-list</id>
    <content type="html"><![CDATA[<p>我们有一个需求，需要在Scala中调用JDBC对数据库进行查询。然后将查询的结果ResultSet放到一个自定义结果类SqlResult中：
{% codeblock lang:scala %}
case class SqlResult(name: List[String], value: List[List[String]])
{% endcodeblock %}</p>

<p>SqlResult的第一个构造函数参数存储的是数据表的列名，第二个参数存储数据表的行记录。由于ResultSet是Java中的一个对象，并不支持Scala的常用集合操作，因此这种转换是有必要的。我引入了隐式类（放在一个package object中）来完成这个转换，在转换过程中，由于需要对ResultSet进行遍历，因而引入了一个结果集List。默认情况下，Scala的List是immutable的，因此将其声明为var：
{% codeblock lang:scala %}
package object db {</p>

<pre><code> implicit class ResultSetUtil(rs: ResultSet) {
      private val columnCount = rs.getMetaData.getColumnCount

      def rows: List[List[String]] = {
           var valueList: List[List[String]] = List()
           while (rs.next()) {
                val oneLine = (1 to columnCount).map(rs.getString).toList
                valueList = oneLine :: valueList
           }
           valueList.reverse 
      }

      def columns: List[String] = {
           (1 to columnCount).map(rs.getMetaData.getColumnName).toList
      }
 }
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>有了这个隐式转换，操作ResultSet就变简单了：
{% codeblock lang:scala %}
def query(sql: String): SqlResult = {</p>

<pre><code>stmt = conn.createStatement()
rs = stmt.executeQuery(sql)
SqlResult(rs.columns, rs.rows)
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>由于在前面的实现中，我初始化了一个Immutable的List，因此只能使用::添加每行从ResultSet得到的记录，然后再赋值给valueList。::方法只能将后加入的元素放到List的头部。所以在遍历完毕后，还需要做一个reverse操作。</p>

<!-- more -->


<p>我的感觉告诉我，这种先添加再反转的做法有些怪异。既然这里是以var的方式来使用Immutable List，为何不直接使用Mutable的集合呢？于是，我将前面的rows方法修改为：
{% codeblock lang:scala %}
import scala.collection.mutable.ListBuffer
package object db {</p>

<pre><code> implicit class ResultSetUtil(rs: ResultSet) {

      def rows: List[List[String]] = {
           val valueList: ListBuffer[List[String]] = ListBuffer()
           while (rs.next()) {
                val oneLine = (1 to columnCount).map(rs.getString).toList
                valueList += oneLine
           }
           valueList.toList  
      }
}
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>因为rows方法返回的是Immutable List，所以在后面需要调用一个转换方法，将ListBuffer转换为List；但这个实现减少了对reverse方法的调用。于是，我产生了一个疑惑：这两种实现，究竟谁的性能更好呢？</p>

<p>为了判断彼此的性能，我首先写了一段简单的小代码，并放到perf.scala文件中：
{% codeblock lang:scala %}
import java.util.Date
import scala.collection.mutable.ListBuffer</p>

<p>object PerformanceTest extends App {</p>

<pre><code>val maxCount = args.head.toInt

args.tail.head match {
    case "list" =&gt;
        println("using List:")
        var time = elapsedTime{ max =&gt;
           var l = List[Int]()
            (1 to max).foreach {
               i =&gt; i :: l
          }
          l.reverse
      }
      println(s"it elapsed $time(ms)")

   case "listbuffer" =&gt;
        println("using ListBuffer:")
         time = elapsedTime{ max =&gt;
            var l = ListBuffer[Int]()
            (1 to max).foreach {
                i =&gt; l += i
            }
            l.toList
        }
        println(s"it elapsed $time(ms)")
}

def elapsedTime(f: Int =&gt; List[Int]):Long = {
    val before = new Date().getTime
    f(maxCount)
    val after = new Date().getTime
    after - before
}
</code></pre>

<p>}
{% endcodeblock %}</p>

<p>为避免前后干扰，我选择以分支的方式通过传入参数分别执行。编译perf.scala文件。运行scala PerformanceTest 100000 list。此时运行结果为：
{% codeblock %}
using List:
it elapsed 23(ms)
{% endcodeblock %}</p>

<p>运行scala PerformanceTest 100000 listbuffer。运行结果为：
{% codeblock %}
using ListBuffer:
it elaspse 26(ms)
{% endcodeblock %}</p>

<p>增加到200,000，结果迥然不同：
{% codeblock %}
using List:
it elaspse 23(ms)
using ListBuffer:
it elaspse 34(ms)
{% endcodeblock %}</p>

<p>增加到500,000，结果迥然不同：
{% codeblock %}
using List:
it elaspse 34(ms)
using ListBuffer:
it elaspse 293(ms)
{% endcodeblock %}</p>

<p>增加到1,000,000，结果就更明显了：
{% codeblock %}
using List:
it elaspse 45(ms)
using ListBuffer:
it elaspse 620(ms)
{% endcodeblock %}</p>

<p>我们假定List方式为A，ListBuffer方式为B。整体看来，方式A消耗的时间都要小于方式B。当数据量越来越大时，这种差距就更加明显。问题在哪里？让我们来看看List与ListBuffer的实现。</p>

<p>首先，考察List对::以及reverse的实现：
{% codeblock lang:scala %}
  def ::[B >: A] (x: B): List[B] =</p>

<pre><code>new scala.collection.immutable.::(x, this)
</code></pre>

<p>  override def reverse: List[A] = {</p>

<pre><code>var result: List[A] = Nil
var these = this
while (!these.isEmpty) {
  result = these.head :: result
  these = these.tail
}
result
</code></pre>

<p>  }
{% endcodeblock %}</p>

<p>::方法中的scala.collection.immutable.::实际上是一个继承自List的样例类。显然，这里的添加操作就相当于对List对象的创建。每次::操作的时间复杂度为O(C1)。此时的常量值C1基本等于1。由于每次遍历都要执行，因此总的时间为O(C1)*n。事实上，List数据结构增加一个头元素本身就非常简单，基本不耗时。但reverse操作要稍微复杂一些。它同样是复制了一个List，但对原List进行了遍历，然后将原有List的头元素与空List进行::操作，使其变成了last元素，如此遍历。因而时间复杂度为O(n)。</p>

<p>再来考察ListBuffer对+=以及toList的实现：
{% codeblock lang:scala %}
  override def toList: List[A] = {</p>

<pre><code>exported = !start.isEmpty
start
</code></pre>

<p>  }</p>

<p>  def += (x: A): this.type = {</p>

<pre><code>if (exported) copy()
if (start.isEmpty) {
  last0 = new :: (x, Nil)
  start = last0
} else {
  val last1 = last0
  last0 = new :: (x, Nil)
  last1.tl = last0
}
len += 1
this
</code></pre>

<p>  }
{% endcodeblock %}</p>

<p>toList方法非常简单，因为ListBuffer内部存储了一个List对象，即这里看到的start。start会在每次添加元素时发生变化。因此看起来是一个转换方法，实则就是返回一个字段。时间复杂度为O(1)。再来看+=操作。首先，该方法会判断exported的值。如果为true，则需要执行copy方法。但是，根据OderSky对+=方法的描述（原书513页），只有在将ListBuffer转换为List之后，如果还要对原ListBuffer执行+=操作，才会执行copy方法：
{% blockquote %}
However, the implementation of ListBuffer is such that copying is neces- sary only for list buffers that are further extended after they have been turned into lists. This case is quite rare in practice. Most use cases of list buffers add elements incrementally and then do one toList operation at the end. In such cases, no copying is necessary.
{% endblockquote %}</p>

<p>根据前面列出的toList方法，也可以看到：只要ListBuffer不为空，exported在执行了toList方法后，才会被设置为true。因此，在我们这个例子里，copy方法是不会执行的。显然，+=方法的执行耗时还是体现在if分支上。注意，这里的start类型为List[A]类型，且被声明为var；last0类型为::，同样被声明为var。在上面的语句中，将last0赋值给start，以及将last0赋值给val对象last1，是关键。此时，只要对last1的tl（即tail，声明为var的scala包下可访问的构造函数参数）进行赋值，实则就是会为start增加尾部元素。所以增加一个新元素，其时间复杂度应该为O(C2)，并且这个C2一定大于1。针对我们的例子，每次遍历都要执行+=方法，因此总的时间复杂度为O(C2)*n。</p>

<p>这个推断是比较符合事实的。Odersky的著作Programming in Scala的第24章列出了各种集合的时间复杂度：
{% img center /images/2014/scalacollection.png %}</p>

<p>比较方案A的O((C+1)n)，要判断谁更优，就是要看各自的C值是多大。分析实现，显然C2 > C1。此外，我们还不要忽略内存的消耗。仔细观察ListBuffer的实现，主要通过var变量start、last0以及一个临时的val变量last0，完成+=操作。相比较List而言，消耗的内存要大得多。事实上，在我将JVM的最大内存设置为512M的前提下，当数值为10,000,000时，执行方式A，消耗时间为119ms，而执行方式B时，就已经抛出OutOfMemoryError的异常了。</p>

<p>显然，当数据量比较大，且性能敏感时，在本文提到的场景下，应优先考虑使用List结合reverse的方式。当然，请注意，这里我虽然使用了Immutable的List，但我将其声明为了var变量。这可以避免在遍历过程中生成临时的List对象。如果采用纯函数无副作用的foldLeft进行转换，例如：
{% codeblock lang:scala %}
var l = (1 to max).foldLeft(List<a href="">Int</a>)((a, b) => b :: a )
l.reverse
{% endcodeblock %}</p>

<p>则其性能比较方式A有非常大的区别，数据量为1,000,000时，达到了845ms。而且在同等环境下，数据量达到5,000,000时，就已经抛出OutOfMemoryError的异常了。</p>

<p>看来，在Scala中操作集合并非易事。尤其是需要考虑性能和内存消耗时，更需要小心谨慎。事实上，我同时还比较了ArrayBuffer以及Vector在这种场景下的性能，都远不如这里列出的A方式。而采用foldLeft方式带来的问题更是我之前没有想到的。一定有优化的空间，也一定有更好的最佳实践。必须注意的是，本文主要比较的是添加元素的操作，且A方式的添加为preappend，B方式则为append。对于不同的集合，也有自身的适用场景。希望将来有时间整理一下这些集合操作在性能上的表现，从而选择合理的集合以及操作方式。</p>
]]></content>
  </entry>
  
</feed>
