<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Architecture | 简单文本]]></title>
  <link href="http://agiledon.github.com/blog/categories/architecture/atom.xml" rel="self"/>
  <link href="http://agiledon.github.com/"/>
  <updated>2014-02-22T23:05:44+08:00</updated>
  <id>http://agiledon.github.com/</id>
  <author>
    <name><![CDATA[张逸]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[可视化架构与DDD]]></title>
    <link href="http://agiledon.github.com/blog/2014/01/09/visualization-architecture-and-ddd/"/>
    <updated>2014-01-09T13:57:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2014/01/09/visualization-architecture-and-ddd</id>
    <content type="html"><![CDATA[<p>从DDD的角度，领域逻辑的分析可以运用战略方法Bounded Context。可是，一个问题是：<strong>如何获得Bounded Context ？</strong></p>

<p>我查看了许多关于Bounded Context的书籍与文章，虽然都着重强调了它的重要性，也给出了一些实例，却对如何从需求——>Boundex Context这一点上语焉不详。</p>

<p>我的初步设想是通过绘制场景图（但并不成熟）。我认为有三种绘制场景图的方式：商业画布，体验地图和流程图。我认为，商业画布可以作为需求分析（尤其针对初创产品）的起点。商业画布如下图所示：
{% img center /images/2014/business_canvas.jpeg %}</p>

<p>采用这种规范化的方式来推导商业模型，可以激发我们的灵感，理清我们的思路，以便我们思考为何要做这个产品，产品应该具备哪些功能。结合优点和缺点、成本等因素，我们可以藉此判断和决策功能的优先级，从而得到MVP。这个过程需要大量运用即时贴，让整个商业模型呈现。经过取舍后，就可以针对产品绘制场景图。此时，场景图可以采用Experience Map或流程图来体现。Experience Map的例子如下图所示：
{% img center /images/2014/experience_map.gif %}</p>

<p>由于商业画布本身提供了“客户”项，我们应该创建Persona，找准人物角色的特征来“搜寻”需求。绘制了场景图后，就能够确定用例了，此时，可辅以ATDD帮助确定Story。在确定了用例后，可以识别Bounded Context，并通过Context Map确定上下文之间的关系。</p>

<!--more-->


<p>就我个人感觉，体验地图还是从Persona的角度设想系统如何使用，考虑它的用户体验。它其实符合“场景”的概念。这里可能还是要考虑：在一个完整的场景中，需要哪些参与者？但是，即使从粗粒度的角度出发，场景都可能存在多个，可能需要绘制多个场景图来逐步提炼Bounded Context。</p>

<p>关于如何运用Persona，我的同事熊子川在他的博客《<a href="http://www.tuzei8.com/2011/06/xd%E5%85%B3%E9%94%AE%E5%AD%975-persona/">XD关键字5：Persona</a>》中已有详细介绍，同样在他的博客《<a href="http://www.tuzei8.com/2012/06/agile-ux-content-strategy/">Agile UX内容策略工作坊</a>》中提出的“消费者建模”实践，指出：</p>

<blockquote><p>为了更好的理解我们选择的目标消费者，我们需要对消费者进行完整的建模，即Persona。越接近于真实的Persona帮助我们更好的理解其用户目标……Persona的重要产出物是一系列用户目标，对于同一个Persona，用户目标可能有不同，有些目标是基础核心目标，有些则是衍生性的，例如一个访问网站潜在投资者的核心目标可能是了解成为投资者的过程，而衍生性目标可能是获得一些关于公司历史信息增加信任度。</p></blockquote>

<p>{% img center /images/2014/persona.jpg %}
<strong>说明</strong>：本图摘自熊子川博客</p>

<p>假设我们要开发一个电子商务网站，我们就可以通过商业画布来驱动出这个产品应该具有哪些功能，它的客户有哪些等，在绘制了场景图后，可以初步得到这样的Bounded Context:
{% img center /images/2014/bounded_context.jpg %}</p>

<p>然后，我利用Context Map得到了各个上下文之间的关系：
{% img center /images/2014/context_map.jpg %}</p>

<p>这样，一个包图的获得就水到渠成了：
{% img center /images/2014/modules.jpeg %}</p>

<p>在识别了Bounded Context以及Context之间的关系后，我们可以运用Hexagon架构（Cockburn提出的六边形架构）来展现系统的整体架构。Hexagon架构并不深入关注内部边界中领域部分，仅仅是简单的划分为Application与Domain两层。但它有助于我们获得基础设施层以及相关集成点的包结构。我们要合理地运用六边形架构。它更贴近应用逻辑架构，并可以驱动我们去发现诸多集成点，寻找集成模式。内外边界的分离也有助于我们将业务逻辑与应用逻辑分离开。这实际上符合“关注点分离”的架构原则。下图展现了六边形架构中常见的Port与Adapter：
{% img center /images/2014/Hexagon.jpg %}</p>

<p>我对“可视化架构”的理解，还是要希望多通过即时贴、白板等工具来实现可视化，而非通过绘图。至少，绘图不应该成为主要的驱动力，否则，开发人员很难接受。例如，下图就是我运用Hexagon架构，并结合可视化手段分析该电子商务系统得到的应用逻辑架构，它很好地一个展现了Hexagon架构的可视化手法。
{% img center /images/2014/e_commerce.jpg %}</p>

<p>在这个图中，直观地展现了如何与外部的支付系统以及物流系统的集成。例如，图中展现的Port实际上为防腐层（ACL）。为何要建立这样的一个防腐层呢，原因在于：支付与物流常常存在多个供应商，因而需要解除对供应商的绑定，并避免供应商系统的变化造成对电子商务系统的腐蚀。这是切合实际的决策。</p>

<p>这个电子商务系统需要与仓库管理系统集成。恰好在《面向模式的软件架构》卷四的第35页，给出了一个仓库管理流程控制系统的案例。书中描述的非功能性需求，即所谓质量属性包括：</p>

<blockquote><p>分布性。仓库管理流程控制系统天生就是分布式的。</p>

<p>性能。仓库管理流程控制系统不是一个“绝对的”实时系统，但性能仍与业务息息相关。对系统有整体的吞吐量要求，因此系统必须确保所有的运输指令能够被及时而有效地运行。</p>

<p>可伸缩性。不同仓库其大小可能会有很大的不同，因此仓库管理流程控制系统必须能既支持只有几千个箱子的小仓库，又要支持超过一百万个箱子的大仓库。</p>

<p>可用性。许多仓库操作采用三班倒的24/7模式工作，因此可用性是仓库管理流程控制系统对业务案例支持的关键因素。</p></blockquote>

<p>假设要设计这样的系统以支持这些质量属性。对于分布式而言，书中提出的解决方案是传统的分布式系统解决方案，即引入Broker模式，在本地建立对远程对象的代理。而对于支持并发的领域对象访问而言，则采用了Active Object模式，并引入Leader/Followers并发模型来获得可扩展。</p>

<p>我没有打算引入这么复杂的模式，而仅仅是通过引入消息队列，并为消息队列引入路由的方式，来实现系统的分布式。这其中当然会用到经典的Publisher-Subscriber模式。我对领域逻辑进行了识别，将整个仓库管理流程控制系统的领域逻辑分为三个Bounded Context。</p>

<ul>
<li><p>库存管理</p></li>
<li><p>物流控制</p></li>
<li><p>拓扑管理</p></li>
</ul>


<p>整个架构如下图所示：
{% img center /images/2014/inventory.jpeg %}</p>

<p>对于库存管理而言，我认为它主要支持商品存放信息的数据管理，即获得商品数量、存放位置以及更新这些信息。对于该上下文而言，操作本身比较简单，且耗时较短。若出现大规模并发，其瓶颈也不在于获取或更新仓库信息（当然需要通过测试数据验证），而在于客户下订单后向仓库管理流程控制系统发起的发货请求。</p>

<p>我将发货请求放到了物流控制上下文中，除此之外，它还包括收货以及订单管理等。同时，对于物流控制与拓扑管理功能，基本上与具体的仓库形成了一一对应关系。此外，对于发货请求（或收货请求），并不要求很强的实时性，这使得对这些请求的异步处理成为可能。</p>

<p>物流控制由于牵涉到收货和运货，需要控制仓库的相关设备，并按照仓库的拓扑结构设定设备的路由。这说明物流控制与拓扑控制存在上下游关系，拓扑控制是上游。这两个上下文可以是Customer-Provider的关系。但它们之间不应该存在物理边界。因此，我将这两个上下文放到了同一个六边形中，而将库存管理放到了另一个单独的六边形中，以便于它们各自独立的可伸缩。</p>

<p>在库存管理与物流控制六边形之间，我引入消息队列来应对从库存管理子系统中转发而来的发货请求（发货请求实则又来自于E-Commerce的订单请求）。原则上，我针对一个物理的仓库建立一个单独的消息队列，因此库存管理在发送发货请求时，会根据商品的存放位置以及用户请求的IP地址，获得最优的仓库信息，然后通过Router将消息转发到正确的消息队列中。</p>

<p>一旦收到消息，物流控制系统作为消息队列的订阅者（或侦听器）就可以即使处理信息，进行后续的处理。</p>

<p>针对库存管理而言，我认为它是一个独立的物理边界，因此在可视化手段中，我展现为一个单独的库存管理六边形，如下图所示：
{% img center /images/2014/inventory_2.jpeg %}</p>

<ul>
<li>建立了针对REST服务的端口，对应的适配器为Controller，其目的是支持E-Commerce系统。事实上，我们对E-Commerce系统进行过分析，获得的六边形架构正好与此对接。</li>
<li>建立了针对DB的端口，对应的适配器为DB Gateway，它负责访问库存管理自身的数据库。数据库持久化的消息包括商品的基本信息如SKU、商品名、数量等，以及商品存放的仓库名。</li>
<li>建立了针对Queue的端口，对应的适配器为Message Router，负责将发货请求消息路由到正确的消息队列。</li>
</ul>


<p>物流控制与拓扑管理放在同一个边界中，它是高度可伸缩的独立系统，为展现它的可伸缩性以及它与库存管理之间的集成，我在可视化手段中，展现出两个独立的六边形，如下图所示：
{% img center /images/2014/inventory_3.jpeg %}</p>

<ul>
<li>针对Queue的侦听器端口，对应的适配器为Message Handler。若有必要，如为了更好的支持并发，也可以在此引入Active Object甚至Leader/Followers。</li>
<li>同样提供了针对REST的端口，对应适配器为Controller。它主要是为了支持移动终端设备、Web应用，以便于相关人员直接发出发货或收货请求。</li>
<li>同样提供了DB的端口。这个数据库是对应仓库的专有数据库，与库存管理数据库无关。</li>
<li>提供了针对设备（指仓库的设备，如叉车，箱子，运输车等）的端口，对应适配器为South Gateway。</li>
<li>提供了针对配置文件的端口，对应适配器为Configurer。此功能是为了支持拓扑信息的动态配置。</li>
<li>提供了针对外部物流系统的端口，这里为其建立了Shipping的防腐层，使其能够更好地支持各个不同的物流供应商。</li>
</ul>


<p>目前，我针对可视化架构与设计的手段仍在完善之中，并已经尝试在真实项目中实践以进行验证，并希望能够找到足够简单的方法，为架构师与开发者提供直观而又具有体验价值的沟通方式，并能形成行之有效的设计手段。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AgileChina2003架构演进杂志]]></title>
    <link href="http://agiledon.github.com/blog/2013/07/29/agilechina-magazine/"/>
    <updated>2013-07-29T22:06:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2013/07/29/agilechina-magazine</id>
    <content type="html"><![CDATA[<h3>“架构演进”介绍</h3>

<p>软件系统的架构从来都不是一蹴而就的，它需要在不断的演化中改进设计，甚至做出重要的架构迁移。尤其对于大型软件系统而言，组织管理、软件过程、需求变化、规模扩张、技术迁移、遗留系统等诸多因素都决定着架构的发展，甚至可能是诸多力量的博弈与权衡。</p>

<h3>技术文章</h3>

<h4>演化架构与紧急设计系列</h4>

<p>本系列文章旨在从全新的视角来介绍经常讨论但是又难以理解的软件架构和设计概念。作者 Neal Ford 将通过介绍一些具体示例来帮助您在演化架构和紧急设计的灵活实践中打下坚实的基础。通过将重要的架构和设计决定推迟到最后责任时刻，您可以防止由于不必要的复杂度而降低软件项目质量的问题。点击<a href="http://www.ibm.com/developerworks/cn/java/j-eaed/">链接</a>。</p>

<h4>遗留系统的技术栈迁移</h4>

<p>遗留系统是一个还在运行和使用，但已步入软件生命周期衰老期的软件系统。它可能会因为无法满足新的质量需求，又或者是出于企业战略决策的考虑等诸多原因，需要对其进行技术栈迁移。然而，在迁移过程中，我们既需要满足迁移后的需求，又必须保证原有的系统功能不会受到破坏，这就为技术栈迁移制造了障碍。本文提出运用“风险驱动模型”来完成这一工作。风险驱动模型就是通过识别风险，对风险排定优先级；然后根据风险选定相关技术，再对风险是否得到缓解进行评估的一种架构方法。点击<a href="http://www.infoq.com/cn/articles/legacy-system-migration">链接</a>。</p>

<h4>注重实效的架构师——大胆行前人未行之路</h4>

<p>是什么让架构师们精通自己的技艺？熟练的架构师是如何进行设计的？一次次，有人问起我这些问题，而我也不止一遍的问我自己。很明显，这并不只是软件工程过程、设计方法、技术或是编程的专业程度所决定的。很多架构师具备令人钦佩且完备的技术知识，这确实是使设计成功的必要条件。但是，还是有很多的软件项目失败了，或是在项目的架构中遭受到了严峻的挑战。掌握此道的关键在于架构师是以什么方式实现设计，他们重视什么，他们关注哪些方面以及在这些方面努力着。点击<a href="http://www.infoq.com/cn/articles/pragmatic-architect">链接</a>。</p>

<!--more-->


<h4>可扩展Web架构与分布式系统</h4>

<p>开放源代码已经成为一些大型网站的基本原则。而在这些网站成长的过程中，一些优秀的实践经验和规则也出现在他们的结构中。本文旨在介绍一些在大型网站结构设计的过程中需要注意的关键问题以及实现目标的基础工作。本文侧重于介绍网络系统，尽管一些准则在其他分布式系统中也是适用的。点击<a href="http://www.oschina.net/translate/scalable-web-architecture-and-distributed-systems">链接</a>。</p>

<h4>架构师</h4>

<p>{% img left /images/2013/07/nealford.png %}</p>

<h5>Neal Ford</h5>

<p>Neal Ford是全球IT咨询公司ThoughtWorks的软件架构师。除了常规工作，他做的事情还包括设计和开发应用程序、教学材料、杂志文章、课件和视频/DVD演示，同时还是各种技术书籍的作者或者编辑，其中包括著作The Productive Programmer。他专注于设计和开发大规模企业应用程序，同时，他也是世界开发人员会议的国际知名演说家。
{% img right /images/2013/07/ericevans.png %}</p>

<h5>Eric Evans</h5>

<p>大型业务系统方面的领域建模和设计专家。早20世纪90年代，他就参与了很多项目，基于对象（Object）开发出许多大型的业务系统，并致力于将敏捷过程应用到现实项目中。
此外，Eric Evans还是《领域驱动设计——软件核心复杂性应对之道》一书的作者。在书中他总结了构建上述业务系统相关的经验、原则和技术等。并介绍了一个建模和设计技术的系统，成功的团队应用这一系统可以组装有业务需求的复杂软件系统，并使系统在增大时仍然保持敏捷。
Eric现在是“Domain Language”组织的负责人。该组织是一个咨询小组，它指导和训练团队实施领域驱动设计，帮助他们使自己的开发工作对业务而言更有生产力和更有价值。{% img left /images/2013/07/buschmann.png %}</p>

<h5>FranK Buschmann</h5>

<p>德国慕尼黑西门子技术公司资深技术专家及负责人。Wiley软件设计模式系列图书主编。他的研究领域包括对象技术、软件架构、产品线、模型驱动软件开发和模式。他曾是ANSI C++标准化委员会x3J16的成员，于1996年发起了首届EuroPLoP会议。Frank Buschmann是Pattern-Oriented Software Architecture系列书籍的主要作者。
{% img right /images/2013/07/george.png %}</p>

<h5>Fred George</h5>

<p>Fred George先生在敏捷开发领域颇有声望，在业界有将近40年的开发经验，是国际敏捷领域大师级专家、咨询师、架构师。早年他在IBM工作。退出IBM之后，以独立咨询师的身份在美国工作了十多年。后来他加盟了ThoughtWorks，成为早期致力于推动敏捷开发的一批开发者。现在他离开了ThoughtWorks，在英国的TrafficBroker公司就任解决方案架构师一职。</p>

<h4>推荐书籍</h4>

<p>{% img left /images/2013/07/releaseit.png %}#####Release It!</p>

<p><strong>推荐理由：</strong>Michael Nygard的Releast It!可以看做是处理软件系统质量属性的治病良方。本书常常会以一个具体的实例开始阐述某一个质量属性的关键性，并列出一系列的反模式作为参照和对比，最后再给出正确的模式列表。这种针对问题的叙事方法，使得读者往往能够照方抓药，又因为模式的叙述如此清晰而规范，所以常常能药到病除。正如本书书名所指，这些内容确乎与软件的发布息息相关。</p>

<p>{% img right /images/2013/07/beautifularchitecture.png %}</p>

<h5>Beautiful Architecture</h5>

<p><strong>推荐理由：</strong>全书涵盖的内容广博而宏大，涵盖了架构基本原则、企业级应用架构、系统架构、最终用户应用架构、语言与架构，分列为本书的五大部分，读之会让人产生目不暇接之感。尤其对于术有专攻的程序员来讲，要彻底吃透本书讲解的内容，无疑是一项艰巨的挑战。然而，如果从架构师所必须具备的技能来看，本书的内容其实并没有超出架构的范畴，因为架构师必须要见识广博，你才能针对不同的需求场景，面对不同的实现技术，选出最适合当前场景的恰如其分的架构方案。</p>

<p>{% img right /images/2013/07/eip.png %}</p>

<h5>Enterprise Integation Patterns</h5>

<p><strong>推荐理由：</strong>本书关注企业级软件系统的本质问题，那就是集成。对于采用异步消息传递的集成方案，本书针对不同场景给出了不同的解决方案，并以模式的方式进行概述与归纳。倘若你在设计软件系统时，需要使用异步消息传递的方式对系统进行集成，本书可以成为你的最佳指南。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[处理文件请求限制]]></title>
    <link href="http://agiledon.github.com/blog/2013/06/13/handle-the-limitation-of-requesting-file/"/>
    <updated>2013-06-13T21:29:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2013/06/13/handle-the-limitation-of-requesting-file</id>
    <content type="html"><![CDATA[<p>在我参与的一个项目中，遇见了一个结合功能性需求与非功能性需求，并要求同时满足的场景。它的功能其实很简单，就是需要向系统发出处理文件的请求。文件的处理则涉及到多个数据表的查询，对相关数据的解析，并依照事先设定好的模板填充数据，最后生成PDF文件。一旦文件处理完毕，就可以返回处理后的文件。由于该系统的业务特殊性，这一功能需求会在某个特定时间，迎来数以万计的客户请求。同时，文件处理功能是一个相对漫长的处理过程，且生成的文件较大。在系统的最初版本中，经历过数千人次的并发数，在只有一台服务器的情况下，导致了大量请求的阻塞。同时，由于加载文件和文件读写需要耗费内存，在请求较为频繁的情况下，多次抛出OutOfMemory异常。即使在最好的情况下，服务端响应了客户端请求，也可能花费大量的时间，严重影响了用户体验。</p>

<p>我们希望在后续版本中解决这一问题。然而，现实总是这么残酷。真正处理文件并提供下载功能的系统并不在我们的掌控之中。它是第三方Vendor提供的Web Service，我们开发的系统仅仅涉及到请求的转发，完成对该Web Service的调用；并在获得结果后，将响应（包含了文件流数据）返回给客户端。换言之，我们既不能改善文件处理的实现逻辑，以提高处理的速度；也无法对该Web Service进行水平伸缩，例如通过引入多台服务器建立集群和负载均衡的方式。</p>

<p>遭遇如此场景实属无奈，要得出好的设计决策就好似戴着镣铐跳舞，只有在自己的服务端下功夫。我们首先想到的是限流（throttle）的方式，通过引入一个类似Controller角色的对象RequestHandlerPool，对客户端的请求进行控制。我们可以设定一个阈值，一旦超过该阈值，就将后续的请求放入队列进行排队。这个限流可以采用简单地在内存实现请求池全局对象。当然，也可以考虑引入消息队列中间件。改进后的时序图如下所示：
{% img center /images/2013/06/filehandling.png %}</p>

<p>引入RequestHandlerPool仅仅是对请求进行了限制，从而避免请求过多导致File Cabinet的阻塞，或者导致抛出OutOfMemeory异常。但整体的处理时间并没有得到任何改善。我们首先考虑将该功能分为两阶段。第一阶段是发起对文件的处理请求，第二阶段则是下载处理好的文件。对于耗时较长的文件处理请求，可以考虑使用异步请求，一旦文件处理完毕，就可以通过Callback通知请求者。然而，由于文件处理的时间过长，可能会导致请求者不愿继续等待结果，从而退出系统，形成一次失败的请求。因而，我们考虑系统的Callback可以通过发送邮件的方式通知发出请求的客户，在邮件内容中附带下载地址，以供客户下载。</p>

<p>纵观整个场景，存在太多制肘，我们也没有太多好的解决方案。而且，我们还应该保证这个解决方案足够简单，因为我们需要在尽量短的周期内对原有方案进行改善，以迎接新一期的业务高峰。这些限制不同于架构约束，它常常迫使我们在逼仄的空间中闪转腾挪。我们还必须尽快地实现方案的原型，并营造与真实业务场景相当的数据，对其进行压力测试和性能测试。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[遗留系统的技术栈迁移]]></title>
    <link href="http://agiledon.github.com/blog/2013/04/24/technical-stack-migration-for-legacy-system/"/>
    <updated>2013-04-24T17:55:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2013/04/24/technical-stack-migration-for-legacy-system</id>
    <content type="html"><![CDATA[<p>{% img center /images/2013/04/legacy.png %}
什么是遗留系统（Legacy System）？根据维基百科的定义，遗留系统是一种旧的方法、旧的技术、旧的计算机系统或应用程序[1]。这一定义事实上并没有很好地揭露遗留系统的本质。我认为，遗留系统首先是一个还在运行和使用，但已步入软件生命周期衰老期的软件系统。它符合所谓的“奶牛规则”：奶牛逐渐衰老，最终无奶可挤；然而与此同时，饲养成本却在上升。这意味着遗留系统会逐渐随着时间的推移，不断地增加维护成本。</p>

<p>维护一个软件系统，就需要了解该软件系统的知识。若知识缺失，就意味着这会给维护人员带来极大的障碍和困难。从这个角度讲，所谓“遗留系统”，就是缺少了一部分重要知识，使得维护人员“知其然而不知其所以然”的软件系统。</p>

<p>若要让遗留系统焕发青春，最彻底的做法自然是推倒重来，但这样付出的代价太高；而且，即使对系统重新设计和开发，仍然免不了会重蹈遗留系统的覆辙。或者，可以对遗留系统进行重构，在不修改系统功能的情况下改善系统设计。只是这种重构常常是对系统进行重大扩展或修改的前奏，如无绝对必要，并不推荐这种偿还“技术债务（Technical Debt）”的方式。重构应与开发同时进行，而不应将其作为债务推迟到最后，以至于支付高昂的利息。最后，还有一种方式，则是对遗留系统进行技术栈迁移。<!--more--></p>

<h3>一. 决策技术栈迁移的因素</h3>

<p>那么，为何要进行技术栈迁移呢？是否是原有技术无法满足新的业务需求？对于遗留系统而言，这种情况总是存在，即需要扩展旧有系统的功能来满足新的业务。然而，这一原因并不足以支持做出技术栈迁移的决策。因为，从技术实现的角度来看，无论采取何种技术，都可以实现各种业务功能，无非是付出的成本不同而已 。基本上，这种成本一定会低于技术栈迁移的成本。此外，当今的软件开发，常常会将一个软件系统看做是完整的生态系统，在这个生态系统圈中，完全允许有多种技术平台（包括多种语言，甚至多种数据库范式）存在，只要我们能够合理地划定各个功能（或服务）的边界。</p>

<p>牵涉到架构中的任何一个重大决策，都需要综合考量和权衡，只有充分地识别了风险，才能制订有效的设计决策。个人认为，只有在如下几种情形出现时，才值得进行技术栈迁移。</p>

<h4>原有技术不能保证新的质量需求</h4>

<p>在一个系统的完整生命周期内，系统从诞生到发展，衰老和死亡，与人一样，是不可规避的过程。对遗留系统进行技术栈迁移，无非是希望通过新的技术给旧有系统注入活力，就像器官移植一般，对腐朽的部分进行切除与替换。系统之所以会衰老，会腐朽，原因还在于需求的变化，从而导致系统结构变得庞大而混乱。我们在进行技术决策时，常常是根据当下的需求以及目前现有的技术，结合团队技术能力做出的最符合当时场景的合理决策。因而，技术栈迁移的原因常常是是因为“此一时彼一时”。在当时场景下做出的明智决策，随着时间的推移，会显得不合时宜。这一点在质量需求的满足上，体现得尤为明显。例如，系统对可伸缩性、性能、安全的要求，都可能因为新的质量需求的提出发生变化。而这些质量属性往往靠旧有技术无法解决。RackSpace对日志处理的案例就属于这一场景[2] 。RackSpace的架构对日志的支持，先后经历了三个大版本的演化，从文件服务器到中心数据库，再到MapReduce，每次技术栈的迁移都是质量属性的驱动，不得不为之。</p>

<h4>出于战略的考虑</h4>

<p>这常常是因为企业架构的因素。对于一个企业而言，应该将其IT系统看作是一个整体的生态系统。对于一个正在成长中的企业而言，必然会随着整个企业组织结构、业务体系的变化而影响到IT系统。一般而言，企业IT系统的架构会存在两种情况。第一种情况是从无到有，根据企业架构师与业务架构师的设计，严格按照设计蓝图来规划所有的IT系统。第二种情况则可能是多种不同的系统并存（可能是因为企业采用了并购等方式兼并其他公司业务，也可能是因为不同的业务需要，购买了不同的软件系统）。第一种情况看似美好，但仍有可能发生规划蓝图不能满足需求的可能。第二种情况则处于龙蛇混杂的局面，最后可能导致所谓的“烟囱系统（Stovepipe System）[3]”，需要花大力气对各种系统进行整合。</p>

<p>无论是哪一种情况，一旦做出技术栈迁移的决定，都必然是企业战略上的考虑。当然这种战略指的是IT战略，也可能是企业的整体战略对IT系统产生影响。</p>

<p>我们的一个客户是一家大型的金融企业，提供了多种品牌的保险与银行业务。企业的战略目标是在体现品牌价值的同时，整体展现企业的平台作用。这对于IT系统而言，就意味着需要对各种业务系统进行整合、迁移。整个系统的主要核心是对客户数据的管理，这些数据的管理会影响到整个企业的服务质量、市场推广与产品维护。由于该企业在银行业与保险业的发展壮大，是通过不断的合并与兼并来促进自身的发展。因而在其IT系统中，事实上存在多种不同的系统。客户信息散落在不同系统的数据库中。客户数据的整合，不仅有利于对这些信息的管理，保证数据的一致性，还在于从市场营销角度考虑，可以通过一致的客户信息对客户的情况做出全面了解，制定更好的推广策略。</p>

<h4>原有的技术提供者不再提供支持</h4>

<p>这种情形最是无奈，却时有发生。一种情况是使用的技术（平台、框架）不再被供应商维护，这一点体现在开源项目上更为明显。另一种情况则是所选的技术平台进行了升级，却没有很好地提供向前兼容，使得系统难以随之而升级。在架构设计中，这种绑定具体平台与技术的做法，实际上是反模式的一种，即“供应商锁定（Vendor Lock-In）[4]”。</p>

<h4>使用旧有技术的成本太高</h4>

<p>IT技术并非一定是新技术成本高于旧技术，事实上，随着技术的创新和发展，技术越新，成本越能得到更好的控制。当新旧技术的成本之差，远远高于技术栈迁移的成本，就值得做出迁移的决策了。例如，我们的一个项目需要处理的遗留系统，使用了某软件公司的产品，该产品必须运行在大型服务器上。该产品主要提供客户信息的处理。这是一个存在超过十年以上的产品，之后加入的子系统并未再使用该产品。如今，该产品所支持的客户数量并不多，而每年的产品许可费用以及大型服务器的维护成本都非常高。最后，我们对该产品提供的功能进行了迁移，以渐进地方式逐渐替换了该产品，降低了系统成本。</p>

<h3>二. 引入风险驱动模型</h3>

<p>George Fairbanks提出的风险驱动模型（Risk-Driven Model）非常适合遗留系统的技术栈迁移。所谓“风险驱动模型”，就是通过识别风险，对风险排定优先级；然后根据风险选定相关技术，再对风险是否得到缓解进行评估的一种架构方法[5] 。在对遗留系统进行技术栈迁移时，如果未能事先对迁移过程的风险进行有效识别，就可能为系统引入新的问题，降低系统质量，或者导致迁移的成本过高。</p>

<p>根据我的经验，在对遗留系统进行技术栈迁移时，可以识别的主要风险包括：
{% blockquote %}
遗留系统本身存在的质量问题，例如紧耦合、缺乏足够的测试、系统可维护性差；
缺乏足够的知识来帮助我们理解整个遗留系统；
成本、时间与人力的风险；
对迁移的新技术缺乏充分认识；
迁移能力的不足
{% endblockquote %}</p>

<h3>三. 选择缓解风险的技术</h3>

<p>一旦识别出迁移过程中可能存在的风险，我们就可以有的放矢地选择相关技术，制订降低风险的解决方案。</p>

<h4>寻找丢失的知识</h4>

<p>只有体验过去，才能谋划未来。如果缺乏对遗留系统的足够认识，这种技术栈的迁移就很难取得成功。通常来讲，一个软件系统的知识，主要体现在如下三个方面，如下图所示：
{% img center /images/2013/04/legacy_01.png %}</p>

<p>在这三个方面中，团队成员拥有的知识无疑是最值得寄予厚望的。在迁移过程中，若有了解该系统的团队成员参与，无疑可以做到事半功倍。可惜，这部分知识又是最为脆弱的，它就好似存储在内存中的数据一般，一旦断电就会全盘丢失。遗留系统的问题恰在于此，由于系统过于陈旧，而人员的流动总是比较频繁，在对系统进行迁移时，可能许多当年参与系统开发的成员，已经很难找到。</p>

<p>缺乏团队成员在知识方面的传承，就只能寄希望于文档与代码。文档的问题有目共睹，无论采用多么严谨的文档管理办法，文档与真实的实现总是存在偏差。正如“尽信书不如无书”，文档可以提供参考价值，但绝对不能完全依赖于文档。毫无疑问，代码是最为真实的知识。它不会说谎，但却过于沉迷于细节，要通过代码来了解遗留系统的知识，一方面耗时耗力，另一方面也难免会产生“只见树木不见森林”之叹。</p>

<p>引入自说明的可运行文档，可以有效地将文档与代码结合起来。通过运用业务语言编写功能场景来体现业务需求，完成文档的撰写；同时，它又是可以运行的代码，通过直接调用代码实现，可以完全真实地验证功能是否准确。目前，有许多框架和工具可以支持这种规格文档，例如Java平台下的<a href="http://jbehave.org/">jBehave</a>，Ruby语言编写的<a href="http://cukes.info/">Cucumber</a>，支持HTML格式的<a href="http://www.concordion.org/">Concordion</a>，以及ThoughtWorks的产品<a href="http://www.thoughtworks-studios.com/twist-agile-testing">Twist</a>[6]。</p>

<p>在我们的一个项目中，需要完成系统从WebLogic到JBoss的技术栈迁移。该系统是一个长达十年以上时间的遗留系统。虽然有比较完整的文档说明，但许多具体的业务对于我们而言，还是像一个黑盒，不知道具体的交互行为。此时，我们和客户一起为其建立了一个专门的项目，通过运用jBehave为该系统的业务行为编写可以运行的Story。在编写Story时，我们参考了系统的文档，并根据文档描述的功能建立场景，确定输入和输出，判断系统的行为是否与文档描述一致。事实上，我们在编写Story的过程中，确曾发现系统的真实行为与文档描述不一致的地方。这时，我们会判断这种不一致究竟是缺陷，还是期待的真实行为。在编写Story的过程中，我们寻找回了已经丢失的知识，并进一步熟悉了系统的结构，了解到系统组件的功能以及组件之间的关系。通过这些不断完善的Story，我们逐渐建立起了一个完全反应了真实实现的可运行文档库，它甚至可以取代原来的文档，成为系统的重要知识。</p>

<h4>及时验证，快速反馈</h4>

<p>在对系统进行技术栈迁移时，我们常常会担心修改会破坏原有的功能。尤其是对于大多数遗留系统，普遍存在测试不足，代码紧耦合，可维护性差的特点。虽然遗留系统会因为这些缺点而受人诟病，但不可否认的是，这些遗留系统毕竟经历了长时间的考验，在功能的正确性上已经得到了充分的验证。在迁移到新的技术时，如果不慎破坏了原有功能，引入了新的缺陷，就可能得不偿失了。</p>

<p>为了避免这种情况发生，我们就需要为其建立充分的测试，并通过建立持续集成（Continuous Integration）环境，提供快速反馈的通道。一旦发现新的修改破坏了系统功能，就需要马上修复或者撤销之前的提交。</p>

<p>问题是我们该如何建立测试保护网？为遗留系统建立测试是一件非常痛苦的事情，为了减小工作量，我们首先应该根据技术迁移的目标，缩小和锁定系统的范围。例如，倘若我们要将系统从IBMMQ迁移到JBossMQ，那么就只需要验证那些与消息队列通信的组件。若要将报表迁移到JasperReport，就应该只检测整个系统的报表组件。另一方面，我们应尽量从粗粒度的测试开始入手。一个好消息是，在之前为了寻找失去的知识时建立的可运行文档，事实上可以看作是一种验收测试。它不仅提供了自说明的文档，同时还建立了覆盖率客观的测试保护网。这种验收测试是针对业务行为编写的完整功能场景，更接近业务需求。它的抽象层次相对较高，并不会涉及太多编程细节。即使实现模块（包括类）是紧耦合的，没有明显的单元边界，我们仍然可以为其编写测试。这就可以省去对类与模块进行解耦这一难度颇高的工作。</p>

<p>通常，我们会将这些测试作为持续集成的一个单独pipeline。每次对原有系统的修改，都要触发该pipeline的运行，以期获得及时的反馈。这样，就可以为原有系统建立一个覆盖范围广泛的测试保护网，使得我们可以有信心地对系统进行技术栈迁移。</p>

<p>针对一些核心场景，我们还可以为遗留系统编写集成测试。这种粗粒度的测试不需要对原有代码进行太多的调整或重构，唯一需要付出的努力是对集成测试环境的搭建。</p>

<p>对于遗留系统的集成测试，最好能够支持本地构建。因为若能在本地开发环境运行集成测试，就可以通过在本地运行构建脚本，快速地获得反馈，避免一些集成错误流入到源代码服务器中，导致持续集成Pipeline频繁出现错误。这种快速失败的方式，可以更好地验证错误，降低集成风险。在搭建本地集成环境时，可以选择一些轻量级框架或容器，提高部署性能。例如我们可以在本地运行Jetty这种轻量级的Web服务器，使用HSQL内存数据库来准备数据。对于某些集成极为困难的情况，也可以适当考虑建立Stub。例如对外部服务的依赖，可以建立一个Stub的Web Service。这种方式虽然没有真实地体现集成功能，但它却可以快速地验证系统内部的功能。</p>

<p>倘若因为一些外部约束，我们无法做到完全的本地构建，也应该提供足够的集成环境，采取混合的方式运行构建脚本。例如可以将正在进行迁移的系统运行在本地环境上，而将该系统需要访问的中间件或者数据库放到其他的集成环境下。我们还可以利用构建脚本如Gradle，建立多种部署环境，例如Dev、Local、Stub、Intg等，使得开发人员或测试人员可以根据不同情况运行不同环境的构建脚本。</p>

<h4>做好充分的技术预研</h4>

<p>所谓“技术栈迁移”，必然是指从一种技术迁移到另一种技术。在充分了解系统当前存在的问题后，还需要深思熟虑，选择合理的目标技术。通常，我们会识别出待迁移模块（或系统）希望达到的质量属性，然后就此功能给出候选技术，建立一个用于权衡的矩阵。接着，再对这些待选技术进行技术预研（Spike），预研的结果将作为最终判断的依据。这种决策是有理有据的，可以有效地规避迁移中因为引入新技术带来的风险。下图是我们在一个项目中对文本搜索进行的技术预研结果矩阵。
{% img center /images/2013/04/legacy_02.png %}</p>

<p>因为是技术栈迁移，必然要求目标技术一定要优于现有技术，否则就没有迁移的必要了。通过技术预研，既可以提供可以量化的数据，保证这种迁移是值得的；同时也相当于预先开始对目标技术展开学习和了解，及早发现技术难点和迁移的痛点。</p>

<p>在我曾经参与的一个项目中，我们针对报告生成器模块编写了自己的一个支持并发处理的Batch Job。但随着系统用户数量的逐步增加，在生成报告的高峰期，并发请求数超过了之前架构设计预见的峰值，且每个报告生成所耗费的时间较长。于是，我们计划引入消息队列技术来替换现有的Batch Job。我们对一些候选技术进行了前期预研，这其中包括微软的MSMQ、Apache ActiveMQ以及RabbitMQ，针对并发处理、可维护性、成本、部署、安全、分布式处理以及灾备等多方面进行了综合考虑，如下表所示：
{% img center /images/2013/04/legacy_03.png %}</p>

<p>技术选型从来都不是以单方面的高质量作为评价标准，即使某项技术在多个评判维度上都得到了最高的分数，也未必就是最佳选择。我们必须结合当前项目的具体场景，实事求是地进行判断，以期获得一个恰如其分的迁移方案。</p>

<h4>新旧共存，小步前行</h4>

<p>技术栈迁移的某些特征与架构的演化不谋而合，我们绝对不能奢求获得一个一蹴而就的完美方案，更不能盼望整个迁移过程能够一步到位。尤其针对那些因为战略调整而驱动的技术栈迁移，可能牵涉到架构风格或整个基础设施的修改或调整，单就迁移这一项工作而言，就可能是一个浩大的工程。这时，我们必须要允许新旧共存，通过小步前行的方式逐步以新技术替换旧技术。我们必须保证前进的每一小步，都不会破坏系统的整体功能。这种新旧共存的局面，可能导致在一段时间会出现架构风格或解决方案的不一致，但只要做好整体规划，最终仍能在一致性方面获得完美的答案。</p>

<p>在我们工作的一个项目中，需要将一个独立的系统彻底移除，并将该系统原有的功能集成到另一个系统。需要移除的目标系统目前以Web Service方式提供服务。我们选择的解决方案是渐进地移除该系统。假设待移除的目标系统为Target，要集成的系统为Integration，我们采用了如下的迁移步骤：
1、修改Integration，为其创建与Target提供的Web Service一致的服务接口；
2、让新建立的服务接口的实现调用Target提供的Web Service；
3、修改客户端对Target服务的调用，改为指向新增的Integration服务接口；
4、如果运行一切正常，再将Target中的实现迁移到Integration中；
5、在迁移过程中，提供Toggle开关，可以随时通过改变Toggle的值，选择使用新或旧的调用方式；
6、再次确定采用新的调用方式是否正常，如果正常，彻底去掉原有的实现，移除Target系统。</p>

<p>新旧共存并非一种妥协，而是迁移过程中必须存在的中间状态。Jez Humble介绍了ThoughtWorks产品<a href="http://www.thoughtworks-studios.com/go-continuous-delivery">GO</a>的几次技术栈迁移[7]，包括从iBatis迁移到Hibernate，从Velocity和JsTemplate转向JRuby on Rails的案例。文章提出了一种称为Branch By Abstraction（抽象分支）的迁移方法，执行步骤如下图所示：
{% img center /images/2013/04/legacy_04.png %}</p>

<p>图中的抽象层将客户端（Consumer）与被替换的实现进行了解耦，使得这种替换可以透明地进行。在对抽象层的实现进行替换时，可以规定替换纪律，例如对于新增功能，必须运用新技术提供实现；还可以通过持续集成的验证门自动验证，例如设置旧有技术在系统中的阈值，每次提交都不允许旧有技术的代码量超过这个阈值。整个迁移过程要保证这个阈值是不断减少，绝不能增加。</p>

<h4>理清思路，持续改进</h4>

<p>要完成遗留系统的技术栈迁移，不可避免地需要对代码实现进行修改或重构。这或许是迁移难度最大的一部分内容。我的经验是针对遗留系统进行处理时，不要从一开始就埋首于浩如烟海的代码段中，太多的细节可能会让你迷失其中。若系统是可以运行的，可以首先运行该系统，通过实际操作了解系统的各个功能点、业务流程。这样的直观感受可以最快地帮助你了解该系统：它能够做什么？它能达成什么目标？它的范围是什么？它存在什么问题？</p>

<p>接下来，我们需要从系统架构出发，了解遗留系统的逻辑结构和物理分布，最好能描绘出遗留系统的轮廓图，这可以帮助你从技术的宏观角度剖析遗留系统的结构与组成；然后再结合你对该系统业务的理解，快速地掌握遗留系统。在阅读源代码时，最好能够从主程序入口开始，找到一些主要的模块，了解其大体的设计方式与编码习惯。由于之前对系统架构已有了解，阅读代码时，不应在一开始就去理解代码实现的细节，而应结合架构文档，比对代码实现是否与文档的描述一致，并充分利用自己的技术与经验，找到阅读代码的终南捷径。例如，如果我们知道该系统采用了MVC架构，就可以很容易地根据Url找到对应的Controller对象，并在该对象中寻找业务功能实现的脉络。又例如我们知道系统引入了WCF来支持分布式处理，而我们又非常熟悉WCF，就可以基本忽略系统基础设施的部分，直接了解系统的业务实现。如果系统基于EJB 2.0实现，则完全可以根据EJB提供的Bean的结构，快速地定位到对应的服务接口与实现。这是因为许多框架都规定了一些约束或规范，从这些约束与规范入手，可以做到事半功倍。</p>

<p>在尝试理解代码的过程中，可以通过手工绘制或利用IDE自动生成包图、时序图等可视性强的UML图，帮助我们理解代码结构。Michael Feathers提出可以为遗留代码绘制影响结构图与特征草图[8]，从而帮助我们去梳理程序中各个对象之间的关系，尤其是帮助我们识别依赖，进而利用接缝类型、隐藏依赖等手法去解除依赖。</p>

<p>了解了代码，还需要对代码进行修改。多数情况下，我们需要首先通过重构来改善代码质量。注意，技术栈的迁移并非重构，但重构可以作为迁移工具箱中一件最为重要的工具。例如，我们可以通过Extract Interface，并结合Use Interface Where Possible手法，对一些具体类进行接口提取，并改变对原来具体类对象的依赖。重构时，必须采取“分而治之，小步前进”的策略。可以首先选择实现较为容易，或者独立性较好的模块进行重构。将遗留系统逐步提取为一些可重用的模块与类。其中，对于原有类或模块的调用方，由于在重构时可能会更改接口，因而可以考虑引入Facade模式或Adapter模式，通过引入间接层对接口进行包装或适配，逐渐替换系统，最后演化为一个结构合理的良好系统。需要注意的是，在重构时一定要时刻谨记，我们之所以进行重构，其目的是为了更好地迁移遗留系统的技术栈，而非为了重构而重构，从而偏离我们之前确定的目标。故而，重构与迁移应该是两顶不同的帽子，不能同时进行。</p>

<h3>四. 结束语</h3>

<p>遗留系统的技术栈迁移可能是一个漫长艰苦的过程，它的难度甚至要高于新开发一个系统，这是因为我们常常会挣扎在新旧系统之间，并在不断的妥协、权衡中缓步前行。</p>

<p>它是一个复杂工程，需要参与者了解迁移前后的技术栈知识，掌握或者至少善于分析与理解遗留系统。我们需要审慎地做出技术决策，通过识别迁移过程的风险来驱动整个迁移过程。在决定迁移选择的技术时，要根据这些识别出来的风险对这些候选技术做充分的预研，获得可供参考的度量矩阵。我们还可以引入BDD框架来编写可运行的功能场景，以此来寻找失去的知识，同时兼得验收测试的保护网。</p>

<p>我们可以通过引入持续集成，建立快速反馈环，以避免迁移时做出的改动对原有系统造成破坏。同时，还必须具备技术迁移的能力。我们可以考虑引入一些最佳实践或迁移方法，例如抽象分支、影响结构图、特征草图，运用设计模式和重构手法来改善遗留代码，以利于技术的迁移。当然，团队协作、架构设计、组织管理、进度跟踪等一系列技术与管理实践同样重要，只是这些实践并非技术栈迁移所必须的，而是所有开发过程都必须经历的过程，因而本文不再赘述这些内容。</p>

<p><strong>参考文献：</strong></p>

<p>[1]：<a href="http://en.wikipedia.org/wiki/Legacy_system">http://en.wikipedia.org/wiki/Legacy_system</a>，原文为：“A legacy system is an old method, technology, computer system, or application program.”</p>

<p>[2]：文章<a href="http://highscalability.com/how-rackspace-now-uses-mapreduce-and-hadoop-query-terabytes-data">How Rackspace Now Uses MapReduce And Hadoop To Query Terabytes Of Data</a></p>

<p>[3]：烟囱系统，一种反模式，<a href="http://highscalability.com/how-rackspace-now-uses-mapreduce-and-hadoop-query-terabytes-data">http://sourcemaking.com/antipatterns/stovepipe-system</a>。</p>

<p>[4]：供应商锁定，一种反模式，参见<a href="http://highscalability.com/how-rackspace-now-uses-mapreduce-and-hadoop-query-terabytes-data">http://sourcemaking.com/antipatterns/vendor-lock-in</a>。</p>

<p>[5]：Gorge Fairbanks：<a href="http://www.amazon.com/Just-Enough-Software-Architecture-Risk-Driven/dp/0984618104">Just Enough Software Architecture</a>，参见第3章Risk Driven Model</p>

<p>[6]：以上所述皆为BDD框架或整体工具。</p>

<p>[7]：Jez Humble：<a href="http://continuousdelivery.com/2011/05/make-large-scale-changes-incrementally-with-branch-by-abstraction/">Make Large Scale Changes Incrementally with Branch By Abstraction</a></p>

<p>[8]：Michael Feathers：<a href="http://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052">Working Effectively with Legacy Code</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[可伸缩系统的架构经验]]></title>
    <link href="http://agiledon.github.com/blog/2013/02/27/scalability-system-architecture-lessons/"/>
    <updated>2013-02-27T11:37:00+08:00</updated>
    <id>http://agiledon.github.com/blog/2013/02/27/scalability-system-architecture-lessons</id>
    <content type="html"><![CDATA[<p>{% img center /images/2013/02/scalability.jpg %}</p>

<p>最近，阅读了Will Larson的文章<a href="http://lethain.com/introduction-to-architecting-systems-for-scale/">Introduction to Architecting System for Scale</a>，感觉很有价值。作者分享了他在Yahoo!与Digg收获的设计可伸缩系统的架构经验。在我过往的架构经验中，由于主要参与开发企业软件系统，这种面向企业内部的软件系统通常不会有太大的负载量，太多的并发量，因而对于系统的可伸缩性考虑较少。大体而言，只要在系统部署上考虑集群以及负载均衡即可。本文给了我很多启发，现把本文的主要内容摘译出来，并结合自己对此的理解。</p>

<!--more-->


<p>Larson首先认为，一个理想的系统，对于容量（Capacity）的增长应该与添加的硬件数是线性的关系。换言之，如果系统只有一台服务器，在增加了另一台同样的机器后，容量应该翻倍。以此类推。这种线性的容量伸缩方式，通常被称之为水平伸缩“Horizontal Scalability”。</p>

<p>在设计一个健壮的系统时，自然必须首要考虑失败的情况。Larson认为，一个理想的系统是当失去其中一台服务器的时候，系统不会崩溃。当然，对应而言，失去一台服务器也会导致容量的响应线性减少。这种情况通常被称为冗余“Redundancy”。</p>

<h3>负载均衡</h3>

<p>无论是水平伸缩还是冗余，都可以通过负载均衡来实现。负载均衡就好似一个协调请求的调停者，它会根据集群中机器的当前负载，合理的分配发往Web服务器的请求，以达到有效利用集群中各台机器资源的目的。显然，这种均衡器应该介于客户端与Web服务器之间，如下图所示：
{% img center /images/2013/02/scalability01.png %}</p>

<p>本文提到了实现负载均衡的几种方法。其一是Smart Client，即将负载均衡的功能添加到数据库（以及缓存或服务）的客户端中。这是一种通过软件来实现负载均衡的方式，它的缺点是方案会比较复杂，不够健壮，也很难被重用（因为协调请求的逻辑会混杂在业务系统中）。对此，Larson在文章以排比的方式连续提出问题，以强化自己对此方案的不认可态度：
{% blockquote %}
Is it attractive because it is the simplest solution? Usually, no. Is it seductive because it is the most robust? Sadly, no. Is it alluring because it'll be easy to reuse? Tragically, no.
{% endblockquote %}</p>

<p>第二种方式是采用硬件负载均衡器，例如<a href="http://www.citrix.com/English/ps2/products/product.asp?contentID=21679">Citrix NetScaler</a>。不过，购买硬件的费用不菲，通常是一些大型公司才会考虑此方案。</p>

<p>如果既不愿意承受Smart Client的痛苦，又不希望花费太多费用去购买硬件，那就可以采用一种混合（Hybird）的方式，称之为软件负载均衡器（Software Load Balancer）。Larson提到了<a href="http://haproxy.1wt.eu/">HAProxy</a>。它会运行在本地，需要负载均衡的服务都会在本地中得到均衡和协调。</p>

<h3>缓存</h3>

<p>为了减轻服务器的负载，还需要引入缓存。文章给出了常见的对缓存的分类，分别包括：预先计算结果（precalculating result，例如针对相关逻辑的前一天的访问量）、预先生成昂贵的索引（pre-generating expensive indexes，例如用户点击历史的推荐）以及在更快的后端存储频繁访问的数据的副本（例如<a href="http://memcached.org/">Memcached</a>）。</p>

<h4>应用缓存</h4>

<p>提供缓存的方式可以分为应用缓存和数据库缓存。此二者各擅胜场。应用缓存通常需要将处理缓存的代码显式地集成到应用代码中。这就有点像使用代理模式来为真实对象提供缓存。首先检查缓存中是否有需要的数据，如果有，就从缓存直接返回，否则再查询数据库。至于哪些值需要放到缓存中呢？有<a href="http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used">诸多算法</a>，例如根据最近访问的，或者根据访问频率。使用Memcached的代码如下所示：
{% codeblock lang:python %}
key = "user.%s" % user_id
user_blob = memcache.get(key)
if user_blob is None:</p>

<pre><code>user = mysql.query("SELECT * FROM users WHERE user_id=\"%s\"", user_id)
if user:
    memcache.set(key, json.dumps(user))
return user
</code></pre>

<p>else:</p>

<pre><code>return json.loads(user_blob)
</code></pre>

<p>{% endcodeblock %}</p>

<h4>数据库缓存</h4>

<p>数据库缓存对于应用代码没有污染，一些天才的DBA甚至可以在不修改任何代码的情况下，通过数据库调优来改进系统性能。例如通过配置Cassandra行缓存。</p>

<h4>内存缓存</h4>

<p>为了提高性能，缓存通常是存储在内存中。常见的内存缓存包括Memcached和<a href="http://redis.io/">Redis</a>。不过采用这种方式仍然需要合理的权衡。我们不可能一股脑儿的将所有数据都存放在内存中，虽然这会极大地改善性能，但比较起磁盘存储而言，RAM的代价更昂贵，同时还会影响系统的健壮性，因为内存中的数据没有持久化，容易丢失。正如之前提到的，我们应该将需要的数据放入缓存，通常的算法是<a href="http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used">least recently used</a>，即LRU。</p>

<h4>CDN</h4>

<p>提高性能，降低Web服务器负载的另一种常见做法是将静态媒体放入CDN（Content Distribution Network）中。如下图所示：
{% img center /images/2013/02/scalability02.png %}</p>

<p>CDN可以有效地分担Web服务器的压力，使得应用服务器可以专心致志地处理动态页面；同时，CDN还可以通过地理分布来提高响应请求的性能。在设置了CDN后，当系统接收到请求时，首先会询问CDN以获得请求中需要的静态媒体（通常会通过HTTP Header来配置CDN能够缓存的内容）。如果请求的内容不可用，CDN会查询服务器以获得该文件，并在CDN本地进行缓存，最后再提供给请求者。如果当前网站并不大，引入CDN的效果不明显时，可以考虑暂不使用CDN，在将来可以通过使用一些轻量级的HTTP服务器如<a href="http://nginx.org/">Nginx</a>，为静态媒体分出专门的子域名如static.domain.com来提供服务。</p>

<h4>缓存失效</h4>

<p>引入缓存所带来的问题是如何保证真实数据与缓存数据之间的一致性。这一问题通常被称之为缓存失效（Cache Invalidation）。从高屋建瓴的角度来讲，解决这一问题的办法无非即使更新缓存中的数据。一种做法是直接将新值写入缓存中（通常被称为write-through cache）；另一种做法是简单地删除缓存中的值，在等到下一次读缓存值的时候再生成。</p>

<p>整体而言，要避免缓存实效，可以依赖于数据库缓存，或者为缓存数据添加有效期，又或者在实现应用程序逻辑时，尽量考虑避免此问题。例如不直接使用DELETE FROM a WHERE…来删除数据，而是先查询符合条件的数据，再使得缓存中对应的数据失效，继而根据其主键显式地删除这些行。</p>

<h3>Off-Line处理</h3>

<p>这篇文章还提到了Off-Line的处理方式，即通过引入消息队列的方式来处理请求。事实上，在大多数企业软件系统中，这种方式也是较为常见的做法。在我撰写的文章《<a href="http://agiledon.github.com/blog/2012/12/27/distributed-architecture-based-on-message/">案例分析:基于消息的分布式架构</a>》中，较为详细地介绍了这种架构。在引入消息队列后，Web服务器会充当消息的发布者，而在消息队列的另一端可以根据需要提供消费者Consumer。如下图所示。对于Off-Line的任务是否执行完毕，通常可以通过轮询或回调的方式来获知。
{% img center /images/2013/02/scalability03.png %}</p>

<p>为了更好地提高代码可读性，可以在公开的接口定义中明确地标示该任务是On-Line还是Off-Line。</p>

<p>引入Message Queue，可以极大地缓解Web服务器的压力，因为它可以将耗时较长的任务转到专门的机器上去执行。</p>

<p>此外，通过引入定时任务，也可以有效地利用Web服务器的空闲时间来处理后台任务。例如，通过Spring Batch Job来执行每日、每周或者每月的定时任务。如果需要多台机器去执行这些定时任务，可以引入Spring提供的<a href="https://puppetlabs.com">Puppet</a>来管理这些服务器。Puppet提供了可读性强的声明性语言来完成对机器的配置。</p>

<h4>Map-Reduce</h4>

<p>对于大数据的处理，自然可以引入Map-Reduce。为整个系统专门引入一个Map-Reduce层来处理数据是有必要的。相对于使用SQL数据库作为数据中心的方式，Map-Reduce对可伸缩性的支持更好。Map-Reduce可以与任务的定时机制结合起来。如下图所示：
{% img center /images/2013/02/scalability04.png %}</p>

<h3>平台层</h3>

<p>Larson认为，大多数系统都是Web应用直接与数据库通信，但如果能加入一个平台层（Platform Layer），或许会更好。
{% img center /images/2013/02/scalability05.png %}</p>

<p>首先，将平台与Web应用分离，使得它们可以独立地进行伸缩。例如需要添加一个新的API，就可以添加新的平台服务器，而无需增加Web服务器。要知道，在这样一个独立的物理分层架构中，不同层次对服务器的要求是不一样的。例如，对于数据库服务器而言，由于需要频繁地对磁盘进行I/O操作，因此应保证数据库服务器的IO性能，如尽量使用固态硬盘。而对于Web服务器而言，则对CPU的要求比较高，尽可能采用多核CPU。</p>

<p>其次，增加一个额外的平台层，可以有效地提高系统的可重用性。例如我们可以将一些与系统共有特性以及横切关注点的内容（如对缓存的支持，对数据库的访问等功能）抽取到平台层中，作为整个系统的基础设施（Infrastructure）。尤其对于产品线系统而言，这种架构可以更好地为多产品提供服务。</p>

<p>最后，这种架构也可能对跨团队开发带来好处。平台可以抽离出一些与产品无关的接口，从而隐藏其具体实现的细节。如果划分合理，并能设计出相对稳定的接口，就可以使得各个团队可以并行开发。例如可以专门成立平台团队，致力于对平台的实现以及优化。</p>
]]></content>
  </entry>
  
</feed>
